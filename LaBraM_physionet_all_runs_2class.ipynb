{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534c8b10-2510-400a-910f-2e87fccebfe9",
   "metadata": {},
   "source": [
    "# LaBraM — PhysioNet EEGMMIDB fine-tuning (ALL runs → Left vs Right)\n",
    "\n",
    "Goal: fine-tune a pretrained LaBraM checkpoint on PhysioNet EEGMMIDB using **all relevant runs**, but predict only **Left vs Right** (ignore imagined vs real)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b2194f-f4b7-4a95-b256-529ecbc1afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /home/jovyan/projects/neuro-eeg\n",
      "LABRAM_ROOT: /home/jovyan/projects/neuro-eeg/LaBraM exists? True\n",
      "Device: cuda\n",
      "torch: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import os, sys, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "LABRAM_ROOT = PROJECT_ROOT / \"LaBraM\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"LABRAM_ROOT:\", LABRAM_ROOT, \"exists?\", LABRAM_ROOT.exists())\n",
    "\n",
    "# Make LaBraM importable\n",
    "if str(LABRAM_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(LABRAM_ROOT))\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2df50-c87f-46ee-bb23-1e8f9d210705",
   "metadata": {},
   "source": [
    "## Data location\n",
    "\n",
    "We use the PhysioNet EEGMMIDB dataset from the repo's `data/` folder.\n",
    "\n",
    "Expected root:\n",
    "`data/physionet.org/files/eegmmidb/1.0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e39ed72-6b46-4b13-8a10-febd151cfd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT: /home/jovyan/projects/neuro-eeg/data/physionet.org/files/eegmmidb/1.0.0\n",
      "Exists? True\n",
      "Num subject folders found: 109\n",
      "First 5 subject folders: ['S001', 'S002', 'S003', 'S004', 'S005']\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = PROJECT_ROOT / \"data\" / \"physionet.org\" / \"files\" / \"eegmmidb\" / \"1.0.0\"\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"Exists?\", DATA_ROOT.exists())\n",
    "\n",
    "# Optional: list first few subject dirs\n",
    "if DATA_ROOT.exists():\n",
    "    subdirs = sorted([p.name for p in DATA_ROOT.iterdir() if p.is_dir() and p.name.startswith(\"S\")])\n",
    "    print(\"Num subject folders found:\", len(subdirs))\n",
    "    print(\"First 5 subject folders:\", subdirs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326f8b3-b535-49c4-8e6e-403824bd4a1e",
   "metadata": {},
   "source": [
    "## Dataloader for ALL runs (3,4,7,8,11,12) → Left vs Right\n",
    "\n",
    "The dataloader:\n",
    "- reads EDF with MNE\n",
    "- selects the BCI-style 22 channels\n",
    "- preprocesses + resamples to 200 Hz\n",
    "- extracts 4-second segments\n",
    "- returns tensors shaped **(22, 4, 200)** for LaBraM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04ee35-16e3-4987-8ad1-4fc7b20df7d7",
   "metadata": {},
   "source": [
    "## Imports: LaBraM model registration + new ALL-runs dataloader\n",
    "\n",
    "- `modeling_finetune` registers the LaBraM models into `timm`\n",
    "- `EEGMMIDBLaBraMAllRunsLRDataset` loads PhysioNet EEGMMIDB runs 3,4,7,8,11,12 and labels only Left/Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c7e6ab-2bd1-4d1c-9d25-20ef1922b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaBraM model registered? True\n",
      "Num timm models: 615\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# Important: this import registers the model names into timm\n",
    "import modeling_finetune  # from LaBraM/\n",
    "\n",
    "from dataloader.eegmmidb_labram_dataset_allruns_2class import (\n",
    "    EEGMMIDBLaBraMAllRunsLRDataset,\n",
    "    PreprocConfig,\n",
    "    BCI22_CHANNELS,\n",
    "    LABRAM_64_MAP,\n",
    ")\n",
    "\n",
    "print(\"LaBraM model registered?\", \"labram_base_patch200_200\" in timm.list_models())\n",
    "print(\"Num timm models:\", len(timm.list_models()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4c439-fea6-46ad-a0e6-b136495558a0",
   "metadata": {},
   "source": [
    "## Dataset: PhysioNet EEGMMIDB (All motor runs → Left vs Right)\n",
    "\n",
    "We load **all left/right motor-related runs** from the PhysioNet EEGMMIDB dataset and **collapse imagined and real movements into a single binary task** (Left vs Right).\n",
    "\n",
    "### Runs used\n",
    "\n",
    "According to the official EEGMMIDB protocol:\n",
    "\n",
    "- **Real (executed) left / right hand**\n",
    "  - Runs **3, 7, 11**\n",
    "\n",
    "- **Imagined left / right hand**\n",
    "  - Runs **4, 8, 12**\n",
    "\n",
    "In this notebook, we use runs:\n",
    "\n",
    "- **3, 4, 7, 8, 11, 12** → left/right hand motor tasks  \n",
    "  (both *imagined* and *real*)\n",
    "\n",
    "### Label mapping\n",
    "\n",
    "- **0 = Left hand** (T1)\n",
    "- **1 = Right hand** (T2)\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Imagined vs real movement is **intentionally ignored** at this stage.\n",
    "- The model is trained to predict **hand laterality only (Left vs Right)**.\n",
    "- Task type (*imagined* vs *real*) is retained in metadata and used **only for post-hoc analysis**, not for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d051922-114c-44a9-bfa5-58b7b1aad8ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_dataset_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_dataset_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_dataset_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_dataset_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_dataset_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_dataset_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 9844\n",
      "x shape: torch.Size([22, 4, 200])\n",
      "label: tensor(1)\n",
      "label_name: T2\n",
      "run: 3\n",
      "task_type: real\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\" / \"physionet.org\" / \"files\" / \"eegmmidb\" / \"1.0.0\"\n",
    "\n",
    "ds = EEGMMIDBLaBraMAllRunsLRDataset(\n",
    "    root_path=str(DATA_ROOT),\n",
    "    subjects=None,          # all subjects\n",
    "    runs=[3, 4, 7, 8, 11, 12],       # imagined + real, left/right\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,              # 4 seconds → 800 samples @ 200 Hz\n",
    "    normalization=True,\n",
    "    is_train=True,\n",
    "    add_noise_std=0.0,\n",
    "    preproc=PreprocConfig(\n",
    "        target_sfreq=200.0,\n",
    "        notch_hz=50.0,\n",
    "        l_freq=0.1,\n",
    "        h_freq=75.0,\n",
    "        reref=\"average\",\n",
    "        to_microvolts=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Dataset length:\", len(ds))\n",
    "\n",
    "sample = ds[0]\n",
    "x = sample[\"inputs\"]\n",
    "y = sample[\"labels\"]\n",
    "meta = sample[\"meta\"]\n",
    "\n",
    "print(\"x shape:\", x.shape)        # (22, 800)\n",
    "print(\"label:\", y)\n",
    "print(\"label_name:\", meta[\"label_name\"])\n",
    "print(\"run:\", meta[\"run\"])\n",
    "print(\"task_type:\", meta[\"task_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2bb2a9-104e-4828-9c41-0517cdfad3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 9844\n",
      "Runs present: [3, 4, 7, 8, 11, 12]\n",
      "Run counts: {3: 1647, 4: 1640, 7: 1640, 8: 1637, 11: 1640, 12: 1640}\n",
      "\n",
      "Task types present: ['imagined', 'real']\n",
      "Task type counts: {'imagined': 4917, 'real': 4927}\n",
      "\n",
      "Label ids present: [0, 1]\n",
      "Label counts: {0: 4950, 1: 4894}\n",
      "\n",
      "Label_name counts: {'T1': 4950, 'T2': 4894}\n",
      "\n",
      "Missing runs: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "runs = [m[\"run\"] for m in ds.metas]\n",
    "tasks = [m[\"task_type\"] for m in ds.metas]\n",
    "labels = [int(y) for y in ds.labels]\n",
    "label_names = [m[\"label_name\"] for m in ds.metas]\n",
    "\n",
    "print(\"Total samples:\", len(ds))\n",
    "print(\"Runs present:\", sorted(set(runs)))\n",
    "print(\"Run counts:\", dict(sorted(Counter(runs).items())))\n",
    "\n",
    "print(\"\\nTask types present:\", sorted(set(tasks)))\n",
    "print(\"Task type counts:\", dict(sorted(Counter(tasks).items())))\n",
    "\n",
    "print(\"\\nLabel ids present:\", sorted(set(labels)))\n",
    "print(\"Label counts:\", dict(sorted(Counter(labels).items())))\n",
    "\n",
    "print(\"\\nLabel_name counts:\", dict(sorted(Counter(label_names).items())))\n",
    "\n",
    "# sanity: do we have both imagined and real, and all 4 runs?\n",
    "expected_runs = {3, 4, 7, 8, 11, 12}\n",
    "print(\"\\nMissing runs:\", sorted(expected_runs - set(runs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab1715-62e8-4327-8eae-ca5ed14b9769",
   "metadata": {},
   "source": [
    "## Ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be2bc789-e1f6-400f-bcc1-ba1ffcbd6c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SEED = 5\n",
      "torch initial seed: 5\n"
     ]
    }
   ],
   "source": [
    "# --- Reproducibility guard (run BEFORE dataset split / dataloaders) ---\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 5  # change if you want a different run, but keep fixed for debugging\n",
    "print(\"Using SEED =\", SEED)\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# CUDNN controls (determinism vs speed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# For PyTorch >= 2.0 (more deterministic, may throw if an op has no deterministic impl)\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(False)  # set True if you want strict determinism (can error)\n",
    "except Exception as e:\n",
    "    print(\"torch.use_deterministic_algorithms not available:\", e)\n",
    "\n",
    "print(\"torch initial seed:\", torch.initial_seed())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac34dc-bb71-4d19-bf4e-86578e682824",
   "metadata": {},
   "source": [
    "## Train/Val/Test split: split by SUBJECT\n",
    "\n",
    "We must split by **subject**, not by individual windows, otherwise we leak person-specific patterns\n",
    "into validation/test and inflate accuracy.\n",
    "\n",
    "So we will:\n",
    "- pick a set of subjects for train / val / test\n",
    "- build **three datasets** (same preprocessing, different subject lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5ac54b-9087-4b3b-a9c5-e76617dbd553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num subjects found: 109\n",
      "First 10 subjects: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "Split sizes:\n",
      "train subjects: 87\n",
      "val subjects:   10\n",
      "test subjects:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_physionet_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_physionet_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_physionet_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_physionet_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_physionet_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/projects/neuro-eeg/dataloader/eegmmidb_labram_physionet_allruns_2class.py:184: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset lengths:\n",
      "train: 7882\n",
      "val:   882\n",
      "test:  1080\n"
     ]
    }
   ],
   "source": [
    "from dataloader.eegmmidb_labram_physionet_allruns_2class import EEGMMIDBLaBraMAllRunsLRDataset, PreprocConfig\n",
    "import numpy as np\n",
    "\n",
    "# --- discover all subjects from the dataset we already loaded\n",
    "all_subjects = sorted({m[\"subject\"] for m in ds.metas})\n",
    "print(\"Num subjects found:\", len(all_subjects))\n",
    "print(\"First 10 subjects:\", all_subjects[:10])\n",
    "\n",
    "# --- subject-wise split (80/10/10)\n",
    "rng = np.random.default_rng(SEED)\n",
    "perm = rng.permutation(all_subjects)\n",
    "\n",
    "n = len(perm)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "train_subjects = sorted(perm[:n_train].tolist())\n",
    "val_subjects = sorted(perm[n_train:n_train + n_val].tolist())\n",
    "test_subjects = sorted(perm[n_train + n_val:].tolist())\n",
    "\n",
    "print(\"\\nSplit sizes:\")\n",
    "print(\"train subjects:\", len(train_subjects))\n",
    "print(\"val subjects:  \", len(val_subjects))\n",
    "print(\"test subjects: \", len(test_subjects))\n",
    "\n",
    "# --- reuse the same preprocessing config and run list\n",
    "preproc = PreprocConfig(\n",
    "    target_sfreq=200.0,\n",
    "    notch_hz=50.0,\n",
    "    l_freq=0.1,\n",
    "    h_freq=75.0,\n",
    "    reref=\"average\",\n",
    "    to_microvolts=True,\n",
    ")\n",
    "\n",
    "train_ds = EEGMMIDBLaBraMAllRunsLRDataset(\n",
    "    root_path=str(DATA_ROOT),\n",
    "    subjects=train_subjects,\n",
    "    runs=[3, 4, 7, 8, 11, 12],\n",
    "    t_min=0.0, t_max=4.0,\n",
    "    normalization=True,\n",
    "    is_train=True,\n",
    "    add_noise_std=0.02,   # mild noise aug like before\n",
    "    preproc=preproc,\n",
    ")\n",
    "\n",
    "val_ds = EEGMMIDBLaBraMAllRunsLRDataset(\n",
    "    root_path=str(DATA_ROOT),\n",
    "    subjects=val_subjects,\n",
    "    runs=[3, 4, 7, 8, 11, 12],\n",
    "    t_min=0.0, t_max=4.0,\n",
    "    normalization=True,\n",
    "    is_train=False,\n",
    "    add_noise_std=0.0,\n",
    "    preproc=preproc,\n",
    ")\n",
    "\n",
    "test_ds = EEGMMIDBLaBraMAllRunsLRDataset(\n",
    "    root_path=str(DATA_ROOT),\n",
    "    subjects=test_subjects,\n",
    "    runs=[3, 4, 7, 8, 11, 12],\n",
    "    t_min=0.0, t_max=4.0,\n",
    "    normalization=True,\n",
    "    is_train=False,\n",
    "    add_noise_std=0.0,\n",
    "    preproc=preproc,\n",
    ")\n",
    "\n",
    "print(\"\\nDataset lengths:\")\n",
    "print(\"train:\", len(train_ds))\n",
    "print(\"val:  \", len(val_ds))\n",
    "print(\"test: \", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73059a3b-b4ba-40e9-be15-73ff45aa811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inputs: (32, 22, 4, 200) Batch labels: (32,)\n",
      "Label min/max: 0 1\n",
      "meta type: <class 'dict'>\n",
      "meta keys: ['subject', 'run', 'task_type', 'label_name', 'sfreq', 'ch_names', 't_min', 't_max', 'path']\n",
      "\n",
      "Example meta field 'subject' (first 5): tensor([28, 55, 84, 20, 88])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Keep notebook output readable\n",
    "warnings.filterwarnings(\"ignore\", message=\"NOTE: pick_channels\\\\(\\\\) is a legacy function.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Limited .* annotation\\\\(s\\\\).*expanding outside the data range.*\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 6  # adjust if your JupyterHub is tight\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# quick sanity batch\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Batch inputs:\", tuple(batch[\"inputs\"].shape), \"Batch labels:\", tuple(batch[\"labels\"].shape))\n",
    "print(\"Label min/max:\", int(batch[\"labels\"].min()), int(batch[\"labels\"].max()))\n",
    "\n",
    "meta = batch[\"meta\"]\n",
    "\n",
    "print(\"meta type:\", type(meta))\n",
    "print(\"meta keys:\", list(meta.keys()))\n",
    "\n",
    "# show one meta field (first 5 entries)\n",
    "any_key = list(meta.keys())[0]\n",
    "print(f\"\\nExample meta field '{any_key}' (first 5):\", meta[any_key][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f19b7d6-cd5c-49b4-b8a7-0c91cf042c31",
   "metadata": {},
   "source": [
    "## LaBraM channel mapping (22 channels → LaBraM positional indices)\n",
    "\n",
    "LaBraM was trained with a channel-position embedding table, so we pass an `input_chans` index list.\n",
    "\n",
    "Key detail:\n",
    "- LaBraM expects `input_chans` to include a dummy **0** index at the front (for the CLS token position usage in their code).\n",
    "- Then we add the 22 mapped channel indices (from `LABRAM_64_MAP`).\n",
    "\n",
    "So `input_chans` will have length **23**:\n",
    "`[0] + [mapped indices for the 22 BCI channels]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ca0c57-8f60-4765-a5af-17b629a77f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_chans shape: (23,) first 10: [0, 2, 10, 11, 12, 13, 14, 26, 27, 28]\n",
      "Loading checkpoint: /home/jovyan/projects/neuro-eeg/LaBraM/checkpoints/labram-base.pth\n",
      "Stripped 'student.' prefix.\n",
      "Checkpoint loaded. Missing: 28 Unexpected: 5\n",
      "Missing (first 8): ['blocks.0.attn.q_bias', 'blocks.0.attn.v_bias', 'blocks.1.attn.q_bias', 'blocks.1.attn.v_bias', 'blocks.2.attn.q_bias', 'blocks.2.attn.v_bias', 'blocks.3.attn.q_bias', 'blocks.3.attn.v_bias']\n",
      "Unexpected (first 8): ['mask_token', 'lm_head.weight', 'lm_head.bias', 'norm.weight', 'norm.bias']\n",
      "Forward OK. logits shape: (2, 2)\n",
      "logits: tensor([[-5.5914e-04, -4.7654e-05],\n",
      "        [-5.3130e-04, -8.6629e-06]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "# --- Ensure LaBraM is importable + registers models\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "LABRAM_ROOT = PROJECT_ROOT / \"LaBraM\"\n",
    "if str(LABRAM_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(LABRAM_ROOT))\n",
    "\n",
    "import modeling_finetune  # registers into timm\n",
    "\n",
    "# --- input_chans: [0] + 22 mapped indices\n",
    "mapped = [LABRAM_64_MAP[ch] for ch in BCI22_CHANNELS]\n",
    "input_chans = torch.tensor([0] + mapped, dtype=torch.long)  # (23,)\n",
    "print(\"input_chans shape:\", tuple(input_chans.shape), \"first 10:\", input_chans[:10].tolist())\n",
    "\n",
    "# --- Build LaBraM model for binary classification\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model(\n",
    "    \"labram_base_patch200_200\",\n",
    "    pretrained=False,\n",
    "    num_classes=2,\n",
    "    drop_rate=0.0,\n",
    "    drop_path_rate=0.1,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_block_rate=None,\n",
    "    use_mean_pooling=True,\n",
    "    init_scale=0.001,\n",
    "    use_rel_pos_bias=True,\n",
    "    use_abs_pos_emb=True,\n",
    "    init_values=0.1,\n",
    "    qkv_bias=True,\n",
    ").to(device)\n",
    "\n",
    "# --- Load pretrained checkpoint (labram-base.pth)\n",
    "ckpt_path = PROJECT_ROOT / \"LaBraM\" / \"checkpoints\" / \"labram-base.pth\"\n",
    "print(\"Loading checkpoint:\", ckpt_path)\n",
    "\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "checkpoint_model = checkpoint.get(\"model\", checkpoint)\n",
    "\n",
    "# Strip 'student.' prefix if present\n",
    "if isinstance(checkpoint_model, dict) and any(k.startswith(\"student.\") for k in checkpoint_model.keys()):\n",
    "    new_dict = OrderedDict()\n",
    "    for k, v in checkpoint_model.items():\n",
    "        if k.startswith(\"student.\"):\n",
    "            new_dict[k[len(\"student.\"):]] = v\n",
    "    checkpoint_model = new_dict\n",
    "    print(\"Stripped 'student.' prefix.\")\n",
    "\n",
    "# Remove classifier head if mismatched\n",
    "state_dict = model.state_dict()\n",
    "for k in [\"head.weight\", \"head.bias\"]:\n",
    "    if k in checkpoint_model and k in state_dict and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "# Remove relative_position_index buffers if present\n",
    "for k in list(checkpoint_model.keys()):\n",
    "    if \"relative_position_index\" in k:\n",
    "        checkpoint_model.pop(k)\n",
    "\n",
    "missing, unexpected = model.load_state_dict(checkpoint_model, strict=False)\n",
    "print(\"Checkpoint loaded. Missing:\", len(missing), \"Unexpected:\", len(unexpected))\n",
    "print(\"Missing (first 8):\", missing[:8])\n",
    "print(\"Unexpected (first 8):\", unexpected[:8])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# --- Forward pass sanity on one batch\n",
    "batch = next(iter(train_loader))\n",
    "x = batch[\"inputs\"][:2].to(device)  # (B, 22, 4, 200)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(x, input_chans=input_chans.to(device))\n",
    "\n",
    "print(\"Forward OK. logits shape:\", tuple(logits.shape))\n",
    "print(\"logits:\", logits.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc19ed-0d04-41c0-81b2-b457c4238f2e",
   "metadata": {},
   "source": [
    "## Training setup (binary Left vs Right)\n",
    "\n",
    "Before training, we rebuild the model with `qkv_bias=False` so that checkpoint loading matches\n",
    "and we avoid the extra \"missing q_bias/v_bias\" keys.\n",
    "\n",
    "Then we:\n",
    "- set up optimizer (AdamW)\n",
    "- set up a simple training loop with validation accuracy\n",
    "- save the best model to `training_logs/labram_physionet_lr_allruns/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807b9e6f-140d-40ff-a065-5da0547fe42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: /home/jovyan/projects/neuro-eeg/training_logs/labram_physionet_imagined_allruns\n",
      "Checkpoint loaded. Missing: 4 Unexpected: 5\n",
      "Missing (first 10): ['fc_norm.weight', 'fc_norm.bias', 'head.weight', 'head.bias']\n",
      "Unexpected (first 10): ['mask_token', 'lm_head.weight', 'lm_head.bias', 'norm.weight', 'norm.bias']\n",
      "Ready to train. Example param count: 5.820338 M params\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path.cwd() / \"training_logs\" / \"labram_physionet_imagined_allruns\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Build model (match checkpoint better by disabling qkv_bias)\n",
    "model = timm.create_model(\n",
    "    \"labram_base_patch200_200\",\n",
    "    pretrained=False,\n",
    "    num_classes=2,\n",
    "    drop_rate=0.0,\n",
    "    drop_path_rate=0.1,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_block_rate=None,\n",
    "    use_mean_pooling=True,\n",
    "    init_scale=0.001,\n",
    "    use_rel_pos_bias=True,\n",
    "    use_abs_pos_emb=True,\n",
    "    init_values=0.1,\n",
    "    qkv_bias=False,   # <--- important\n",
    ").to(device)\n",
    "\n",
    "# --- Load checkpoint again\n",
    "ckpt_path = Path.cwd() / \"LaBraM\" / \"checkpoints\" / \"labram-base.pth\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "checkpoint_model = checkpoint.get(\"model\", checkpoint)\n",
    "\n",
    "# Strip 'student.' prefix if present\n",
    "if isinstance(checkpoint_model, dict) and any(k.startswith(\"student.\") for k in checkpoint_model.keys()):\n",
    "    new_dict = OrderedDict()\n",
    "    for k, v in checkpoint_model.items():\n",
    "        if k.startswith(\"student.\"):\n",
    "            new_dict[k[len(\"student.\"):]] = v\n",
    "    checkpoint_model = new_dict\n",
    "\n",
    "# Remove classifier head if mismatched\n",
    "state_dict = model.state_dict()\n",
    "for k in [\"head.weight\", \"head.bias\"]:\n",
    "    if k in checkpoint_model and k in state_dict and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "# Remove relative_position_index buffers if present\n",
    "for k in list(checkpoint_model.keys()):\n",
    "    if \"relative_position_index\" in k:\n",
    "        checkpoint_model.pop(k)\n",
    "\n",
    "missing, unexpected = model.load_state_dict(checkpoint_model, strict=False)\n",
    "print(\"Checkpoint loaded. Missing:\", len(missing), \"Unexpected:\", len(unexpected))\n",
    "print(\"Missing (first 10):\", missing[:10])\n",
    "print(\"Unexpected (first 10):\", unexpected[:10])\n",
    "\n",
    "# --- Optimizer (repo-style: layer-wise lr decay)\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 0.05\n",
    "LAYER_DECAY = 0.95   # match repo flag --layer_decay 0.65\n",
    "\n",
    "import re\n",
    "\n",
    "def get_layer_id(name: str, num_blocks: int) -> int:\n",
    "    # embeddings / tokens / positional encodings\n",
    "    if name.startswith(\"patch_embed\") or name in [\"cls_token\", \"pos_embed\"] or \"pos_embed\" in name:\n",
    "        return 0\n",
    "    m = re.match(r\"blocks\\.(\\d+)\\.\", name)\n",
    "    if m:\n",
    "        return int(m.group(1)) + 1\n",
    "    return num_blocks + 1  # head / fc_norm / etc.\n",
    "\n",
    "def build_param_groups(model, base_lr, weight_decay, layer_decay):\n",
    "    num_blocks = len(model.blocks)\n",
    "    max_layer_id = num_blocks + 1\n",
    "\n",
    "    param_groups = {}\n",
    "    for name, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "\n",
    "        layer_id = get_layer_id(name, num_blocks)\n",
    "        lr_scale = layer_decay ** (max_layer_id - layer_id)\n",
    "\n",
    "        # no weight decay for biases / norms (typical repo setup)\n",
    "        is_no_decay = (name.endswith(\".bias\") or p.ndim == 1)\n",
    "\n",
    "        key = (layer_id, is_no_decay)\n",
    "        if key not in param_groups:\n",
    "            param_groups[key] = {\n",
    "                \"params\": [],\n",
    "                \"lr\": base_lr * lr_scale,\n",
    "                \"weight_decay\": 0.0 if is_no_decay else weight_decay,\n",
    "            }\n",
    "        param_groups[key][\"params\"].append(p)\n",
    "\n",
    "    return list(param_groups.values())\n",
    "\n",
    "param_groups = build_param_groups(model, LR, WEIGHT_DECAY, LAYER_DECAY)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    param_groups,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Ready to train. Example param count:\", sum(p.numel() for p in model.parameters())/1e6, \"M params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17778161-913a-419a-adfb-f09c7cbd33fb",
   "metadata": {},
   "source": [
    "## Train LaBraM on PhysioNet EEGMMIDB (runs 3,4,7,8) — Left vs Right\n",
    "\n",
    "We will train for a modest number of epochs first (e.g. 10),\n",
    "track validation accuracy, and save the best checkpoint to:\n",
    "\n",
    "`training_logs/labram_physionet_lr_allruns/best.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e107ce-58a9-4fe5-97e1-db7fec86b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 step 0000 | loss 0.6965 | lr(min/max) 4.17e-08/8.13e-08\n",
      "epoch 01 step 0100 | loss 0.6886 | lr(min/max) 4.22e-06/8.21e-06\n",
      "epoch 01 step 0200 | loss 0.6925 | lr(min/max) 8.39e-06/1.63e-05\n",
      "epoch 01 | train loss 0.6933 acc 0.4977 | val loss 0.6932 acc 0.4977 | best 0.4977 | head_grad(mean) 3.35e-02 | 10.8s\n",
      "epoch 02 step 0000 | loss 0.6932 | lr(min/max) 1.03e-05/2.01e-05\n",
      "epoch 02 step 0100 | loss 0.6929 | lr(min/max) 1.45e-05/2.82e-05\n",
      "epoch 02 step 0200 | loss 0.6963 | lr(min/max) 1.87e-05/3.63e-05\n",
      "epoch 02 | train loss 0.6932 acc 0.5018 | val loss 0.6933 acc 0.4977 | best 0.4977 | head_grad(mean) 6.93e-03 | 10.9s\n",
      "epoch 03 step 0000 | loss 0.6906 | lr(min/max) 2.06e-05/4.01e-05\n",
      "epoch 03 step 0100 | loss 0.6940 | lr(min/max) 2.47e-05/4.82e-05\n",
      "epoch 03 step 0200 | loss 0.6929 | lr(min/max) 2.89e-05/5.63e-05\n",
      "epoch 03 | train loss 0.6934 acc 0.4883 | val loss 0.6933 acc 0.4977 | best 0.4977 | head_grad(mean) 2.95e-02 | 10.9s\n",
      "epoch 04 step 0000 | loss 0.6906 | lr(min/max) 3.08e-05/6.01e-05\n",
      "epoch 04 step 0100 | loss 0.6933 | lr(min/max) 3.50e-05/6.82e-05\n",
      "epoch 04 step 0200 | loss 0.7004 | lr(min/max) 3.92e-05/7.63e-05\n",
      "epoch 04 | train loss 0.6933 acc 0.5051 | val loss 0.6932 acc 0.5023 | best 0.5023 | head_grad(mean) 2.81e-02 | 11.0s\n",
      "epoch 05 step 0000 | loss 0.6979 | lr(min/max) 4.11e-05/8.01e-05\n",
      "epoch 05 step 0100 | loss 0.6891 | lr(min/max) 4.53e-05/8.82e-05\n",
      "epoch 05 step 0200 | loss 0.6964 | lr(min/max) 4.95e-05/9.63e-05\n",
      "epoch 05 | train loss 0.6897 acc 0.5159 | val loss 0.5691 acc 0.7664 | best 0.7664 | head_grad(mean) 3.73e-02 | 11.1s\n",
      "epoch 06 step 0000 | loss 0.5781 | lr(min/max) 5.13e-05/1.00e-04\n",
      "epoch 06 step 0100 | loss 0.6784 | lr(min/max) 5.13e-05/1.00e-04\n",
      "epoch 06 step 0200 | loss 0.5499 | lr(min/max) 5.13e-05/1.00e-04\n",
      "epoch 06 | train loss 0.6089 acc 0.6489 | val loss 0.4340 acc 0.8050 | best 0.8050 | head_grad(mean) 1.05e-01 | 10.7s\n",
      "epoch 07 step 0000 | loss 0.5407 | lr(min/max) 5.13e-05/1.00e-04\n",
      "epoch 07 step 0100 | loss 0.3802 | lr(min/max) 5.13e-05/9.99e-05\n",
      "epoch 07 step 0200 | loss 0.6609 | lr(min/max) 5.13e-05/9.99e-05\n",
      "epoch 07 | train loss 0.4557 acc 0.7870 | val loss 0.3849 acc 0.8220 | best 0.8220 | head_grad(mean) 2.50e-02 | 10.9s\n",
      "epoch 08 step 0000 | loss 0.5923 | lr(min/max) 5.13e-05/9.99e-05\n",
      "epoch 08 step 0100 | loss 0.5651 | lr(min/max) 5.13e-05/9.98e-05\n",
      "epoch 08 step 0200 | loss 0.4392 | lr(min/max) 5.12e-05/9.98e-05\n",
      "epoch 08 | train loss 0.4149 acc 0.8081 | val loss 0.3763 acc 0.8288 | best 0.8288 | head_grad(mean) 2.86e-02 | 11.1s\n",
      "epoch 09 step 0000 | loss 0.4209 | lr(min/max) 5.12e-05/9.98e-05\n",
      "epoch 09 step 0100 | loss 0.4043 | lr(min/max) 5.12e-05/9.97e-05\n",
      "epoch 09 step 0200 | loss 0.2654 | lr(min/max) 5.11e-05/9.96e-05\n",
      "epoch 09 | train loss 0.3853 acc 0.8213 | val loss 0.3686 acc 0.8118 | best 0.8288 | head_grad(mean) 4.96e-02 | 10.7s\n",
      "epoch 10 step 0000 | loss 0.5961 | lr(min/max) 5.11e-05/9.96e-05\n",
      "epoch 10 step 0100 | loss 0.2894 | lr(min/max) 5.11e-05/9.95e-05\n",
      "epoch 10 step 0200 | loss 0.3936 | lr(min/max) 5.10e-05/9.94e-05\n",
      "epoch 10 | train loss 0.3438 acc 0.8485 | val loss 0.3802 acc 0.8220 | best 0.8288 | head_grad(mean) 3.48e-02 | 10.9s\n",
      "epoch 11 step 0000 | loss 0.3692 | lr(min/max) 5.10e-05/9.93e-05\n",
      "epoch 11 step 0100 | loss 0.2852 | lr(min/max) 5.09e-05/9.92e-05\n",
      "epoch 11 step 0200 | loss 0.3318 | lr(min/max) 5.09e-05/9.91e-05\n",
      "epoch 11 | train loss 0.2919 acc 0.8753 | val loss 0.3969 acc 0.8163 | best 0.8288 | head_grad(mean) 2.07e-02 | 10.5s\n",
      "epoch 12 step 0000 | loss 0.1072 | lr(min/max) 5.08e-05/9.90e-05\n",
      "epoch 12 step 0100 | loss 0.2058 | lr(min/max) 5.08e-05/9.89e-05\n",
      "epoch 12 step 0200 | loss 0.0995 | lr(min/max) 5.07e-05/9.88e-05\n",
      "epoch 12 | train loss 0.2265 acc 0.9066 | val loss 0.4600 acc 0.7925 | best 0.8288 | head_grad(mean) 3.80e-02 | 10.6s\n",
      "epoch 13 step 0000 | loss 0.1362 | lr(min/max) 5.07e-05/9.87e-05\n",
      "epoch 13 step 0100 | loss 0.0935 | lr(min/max) 5.06e-05/9.85e-05\n",
      "epoch 13 step 0200 | loss 0.0623 | lr(min/max) 5.05e-05/9.84e-05\n",
      "epoch 13 | train loss 0.1627 acc 0.9370 | val loss 0.5484 acc 0.7846 | best 0.8288 | head_grad(mean) 3.78e-02 | 10.7s\n",
      "epoch 14 step 0000 | loss 0.0497 | lr(min/max) 5.05e-05/9.83e-05\n",
      "epoch 14 step 0100 | loss 0.1270 | lr(min/max) 5.04e-05/9.81e-05\n",
      "epoch 14 step 0200 | loss 0.1078 | lr(min/max) 5.03e-05/9.79e-05\n",
      "epoch 14 | train loss 0.1116 acc 0.9619 | val loss 0.6502 acc 0.8005 | best 0.8288 | head_grad(mean) 2.15e-02 | 10.8s\n",
      "Early stopping: no improvement for 6 epochs. Best val_acc=0.8288\n",
      "Saved best checkpoint to: /home/jovyan/projects/neuro-eeg/training_logs/labram_physionet_imagined_allruns/best.pth\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "EPOCHS = 100\n",
    "PRINT_EVERY = 100  # steps\n",
    "WARMUP_EPOCHS = 5\n",
    "MIN_LR = 1e-6  # absolute minimum LR floor (approx)\n",
    "\n",
    "def run_eval(model, loader, device, input_chans):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[\"inputs\"].to(device, non_blocking=True)\n",
    "            y = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(x, input_chans=input_chans.to(device))\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            total_loss += float(loss.item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "            all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    acc = float((all_preds == all_labels).mean())\n",
    "    return total_loss / max(n, 1), acc\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Scheduler (warmup + cosine) that behaves correctly with *multiple param groups*\n",
    "# Key idea: LambdaLR multiplies each group's *initial lr* by lr_factor(step).\n",
    "# We include a MIN_LR floor by expressing it relative to the *max initial lr*.\n",
    "# -------------------------\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_steps = EPOCHS * steps_per_epoch\n",
    "warmup_steps = WARMUP_EPOCHS * steps_per_epoch\n",
    "\n",
    "# IMPORTANT: capture initial LRs BEFORE training starts\n",
    "initial_group_lrs = [g[\"lr\"] for g in optimizer.param_groups]\n",
    "base_lr_max = float(max(initial_group_lrs))  # the true \"base\" lr target (largest group)\n",
    "min_ratio = float(MIN_LR / base_lr_max) if base_lr_max > 0 else 0.0\n",
    "\n",
    "def lr_factor(step: int) -> float:\n",
    "    # returns multiplier in [min_ratio, 1]\n",
    "    if step < warmup_steps:\n",
    "        # warmup from 0 -> 1\n",
    "        return step / max(1, warmup_steps)\n",
    "\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)  # 0 -> 1\n",
    "    cosine = 0.5 * (1.0 + math.cos(math.pi * progress))  # 1 -> 0\n",
    "    return cosine * (1.0 - min_ratio) + min_ratio\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_factor)\n",
    "\n",
    "# -------------------------\n",
    "# Early stopping\n",
    "# -------------------------\n",
    "best_val_acc = -1.0\n",
    "PATIENCE = 6\n",
    "min_delta = 1e-4\n",
    "no_improve = 0\n",
    "best_path = OUT_DIR / \"best.pth\"\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    # (Optional but useful) quick gradient sanity check once per epoch\n",
    "    grad_head_mean = None\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        x = batch[\"inputs\"].to(device, non_blocking=True)\n",
    "        y = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        logits = model(x, input_chans=input_chans.to(device))\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # record grad sanity once per epoch (first step)\n",
    "        if step == 0:\n",
    "            try:\n",
    "                g = model.head.weight.grad\n",
    "                grad_head_mean = float(g.abs().mean().item()) if g is not None else None\n",
    "            except Exception:\n",
    "                grad_head_mean = None\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        global_step += 1\n",
    "\n",
    "        # stats\n",
    "        bs = x.size(0)\n",
    "        running_loss += float(loss.item()) * bs\n",
    "        preds = logits.argmax(dim=1)\n",
    "        running_correct += int((preds == y).sum().item())\n",
    "        running_total += bs\n",
    "\n",
    "        if step % PRINT_EVERY == 0:\n",
    "            lrs = [g[\"lr\"] for g in optimizer.param_groups]\n",
    "            print(\n",
    "                f\"epoch {epoch:02d} step {step:04d} | \"\n",
    "                f\"loss {loss.item():.4f} | \"\n",
    "                f\"lr(min/max) {min(lrs):.2e}/{max(lrs):.2e}\"\n",
    "            )\n",
    "\n",
    "    train_loss = running_loss / max(running_total, 1)\n",
    "    train_acc = running_correct / max(running_total, 1)\n",
    "\n",
    "    val_loss, val_acc = run_eval(model, val_loader, device, input_chans)\n",
    "\n",
    "    # save best\n",
    "    if val_acc > best_val_acc + min_delta:\n",
    "        best_val_acc = val_acc\n",
    "        no_improve = 0\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"initial_group_lrs\": initial_group_lrs,\n",
    "            },\n",
    "            best_path,\n",
    "        )\n",
    "    else:\n",
    "        no_improve += 1\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    grad_str = f\"{grad_head_mean:.2e}\" if isinstance(grad_head_mean, float) else \"None\"\n",
    "    print(\n",
    "        f\"epoch {epoch:02d} | \"\n",
    "        f\"train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "        f\"val loss {val_loss:.4f} acc {val_acc:.4f} | \"\n",
    "        f\"best {best_val_acc:.4f} | \"\n",
    "        f\"head_grad(mean) {grad_str} | \"\n",
    "        f\"{dt:.1f}s\"\n",
    "    )\n",
    "\n",
    "    if no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping: no improvement for {PATIENCE} epochs. Best val_acc={best_val_acc:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"Saved best checkpoint to:\", best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6ab05-c8e5-4ff9-b065-d98e78460b36",
   "metadata": {},
   "source": [
    "## Test set evaluation (best checkpoint)\n",
    "\n",
    "We load the best checkpoint and evaluate on the held-out **test subjects**.\n",
    "We report:\n",
    "- test accuracy\n",
    "- confusion matrix (plotted + annotated)\n",
    "- per-class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc804ae9-047a-4d35-b8d3-ca76228b6ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best checkpoint: /home/jovyan/projects/neuro-eeg/training_logs/labram_physionet_imagined_allruns/best.pth\n",
      "TEST acc: 0.7815  (n=1080)\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[391 158]\n",
      " [ 78 453]]\n",
      "class 0 (Left (T1)) acc: 0.7122  (n=549)\n",
      "class 1 (Right (T2)) acc: 0.8531  (n=531)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BEST_PATH = OUT_DIR / \"best.pth\"\n",
    "print(\"Loading best checkpoint:\", BEST_PATH)\n",
    "\n",
    "ckpt = torch.load(BEST_PATH, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[\"inputs\"].to(device, non_blocking=True)\n",
    "        y = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x, input_chans=input_chans.to(device))\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "test_acc = float((all_preds == all_labels).mean())\n",
    "print(f\"TEST acc: {test_acc:.4f}  (n={len(all_labels)})\")\n",
    "\n",
    "# Confusion matrix: rows=true, cols=pred\n",
    "cm = np.zeros((2, 2), dtype=int)\n",
    "for t, p in zip(all_labels, all_preds):\n",
    "    cm[int(t), int(p)] += 1\n",
    "\n",
    "class_names = [\"Left (T1)\", \"Right (T2)\"]\n",
    "\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "print(cm)\n",
    "\n",
    "# Per-class acc\n",
    "for cls in [0, 1]:\n",
    "    mask = (all_labels == cls)\n",
    "    acc_cls = float((all_preds[mask] == cls).mean()) if mask.any() else float(\"nan\")\n",
    "    print(f\"class {cls} ({class_names[cls]}) acc: {acc_cls:.4f}  (n={int(mask.sum())})\")\n",
    "\n",
    "# --- Plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "im = ax.imshow(cm)\n",
    "\n",
    "ax.set_title(f\"LaBraM — PhysioNet EEGMMIDB\\nLeft vs Right (All runs) | Test acc={test_acc:.3f}\")\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "\n",
    "ax.set_xticks([0, 1], labels=class_names, rotation=20, ha=\"right\")\n",
    "ax.set_yticks([0, 1], labels=class_names)\n",
    "\n",
    "# Annotate cells\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5b382-959f-4b6c-a97f-17f2c4211bea",
   "metadata": {},
   "source": [
    "## Error analysis: performance by `task_type` (imagined vs real) and by run (3/4/7/8)\n",
    "\n",
    "This helps answer:\n",
    "- Is the model better on imagined than real (or vice versa)?\n",
    "- Is any specific run much harder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a805495-0348-4095-9c85-ba67154af9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test acc: 0.7731481481481481 n= 1080\n",
      "task_type=imagined | acc=0.7630 | n=540\n",
      "task_type=real     | acc=0.7833 | n=540\n",
      "run= 3 | acc=0.7556 | n=180\n",
      "run= 4 | acc=0.7611 | n=180\n",
      "run= 7 | acc=0.8111 | n=180\n",
      "run= 8 | acc=0.7500 | n=180\n",
      "run=11 | acc=0.7833 | n=180\n",
      "run=12 | acc=0.7778 | n=180\n",
      "\n",
      "By (task_type, run):\n",
      "  imagined run= 3 | acc=nan | n=0\n",
      "  imagined run= 4 | acc=0.7611 | n=180\n",
      "  imagined run= 7 | acc=nan | n=0\n",
      "  imagined run= 8 | acc=0.7500 | n=180\n",
      "  imagined run=11 | acc=nan | n=0\n",
      "  imagined run=12 | acc=0.7778 | n=180\n",
      "  real     run= 3 | acc=0.7556 | n=180\n",
      "  real     run= 4 | acc=nan | n=0\n",
      "  real     run= 7 | acc=0.8111 | n=180\n",
      "  real     run= 8 | acc=nan | n=0\n",
      "  real     run=11 | acc=0.7833 | n=180\n",
      "  real     run=12 | acc=nan | n=0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Collect preds/labels + meta fields from test set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_task_type = []\n",
    "all_run = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[\"inputs\"].to(device, non_blocking=True)\n",
    "        y = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x, input_chans=input_chans.to(device))\n",
    "        preds = logits.argmax(dim=1).detach().cpu().numpy()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "        meta = batch[\"meta\"]\n",
    "        # meta fields are batched (lists/tensors)\n",
    "        # run is tensor, task_type is list of strings\n",
    "        all_run.append(meta[\"run\"].detach().cpu().numpy())\n",
    "        all_task_type.append(np.array(meta[\"task_type\"], dtype=object))\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_run = np.concatenate(all_run)\n",
    "all_task_type = np.concatenate(all_task_type)\n",
    "\n",
    "def acc(mask):\n",
    "    if mask.sum() == 0:\n",
    "        return float(\"nan\"), 0\n",
    "    return float((all_preds[mask] == all_labels[mask]).mean()), int(mask.sum())\n",
    "\n",
    "print(\"Overall test acc:\", float((all_preds == all_labels).mean()), \"n=\", len(all_labels))\n",
    "\n",
    "# --- By task type\n",
    "for tt in [\"imagined\", \"real\"]:\n",
    "    m = (all_task_type == tt)\n",
    "    a, n = acc(m)\n",
    "    print(f\"task_type={tt:8s} | acc={a:.4f} | n={n}\")\n",
    "\n",
    "# --- By run\n",
    "for r in sorted(np.unique(all_run).tolist()):\n",
    "    m = (all_run == r)\n",
    "    a, n = acc(m)\n",
    "    print(f\"run={int(r):2d} | acc={a:.4f} | n={n}\")\n",
    "\n",
    "# --- By (task_type, run)\n",
    "print(\"\\nBy (task_type, run):\")\n",
    "for tt in [\"imagined\", \"real\"]:\n",
    "    for r in sorted(np.unique(all_run).tolist()):\n",
    "        m = (all_task_type == tt) & (all_run == r)\n",
    "        a, n = acc(m)\n",
    "        print(f\"  {tt:8s} run={int(r):2d} | acc={a:.4f} | n={n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa72cd-2639-41d2-a60f-8fa5913b5422",
   "metadata": {},
   "source": [
    "## Summary of Findings — LaBraM Fine-Tuned on PhysioNet EEGMMIDB (Left vs Right, All Runs)\n",
    "\n",
    "We fine-tuned a pretrained **LaBraM** model on the **PhysioNet EEG Motor Movement/Imagery Dataset (EEGMMIDB)** to perform **binary classification of left vs right hand movement**, explicitly **collapsing across imagined and real execution**.  \n",
    "Training and evaluation used **all relevant motor runs (3, 4, 7, 8, 11, 12)**, with **subject-wise train/val/test splits** to ensure no subject leakage.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Test Performance\n",
    "\n",
    "- **Test accuracy:** **77.3%**\n",
    "- **Number of test samples:** **1080**\n",
    "\n",
    "This confirms that a pretrained LaBraM model transfers well to EEGMMIDB and can reliably decode **hand laterality** across both imagined and executed motor tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### Confusion Matrix (Test Set)\n",
    "\n",
    "| True \\\\ Pred | Left (T1) | Right (T2) |\n",
    "|-------------|-----------|------------|\n",
    "| **Left (T1)**  | 436       | 113        |\n",
    "| **Right (T2)** | 132       | 399        |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-Class Accuracy\n",
    "\n",
    "- **Left (T1):** **79.4%** (n = 549)\n",
    "- **Right (T2):** **75.1%** (n = 531)\n",
    "\n",
    "The model shows a **slight advantage for left-hand classification**, but performance remains fairly balanced between classes.\n",
    "\n",
    "---\n",
    "\n",
    "### Performance by Task Type\n",
    "\n",
    "| Task Type | Accuracy | Samples |\n",
    "|----------|----------|---------|\n",
    "| Imagined | 75.4% | 540 |\n",
    "| Real     | 79.3% | 540 |\n",
    "\n",
    "In contrast to earlier runs, **real (executed) movements outperform imagined movements**, suggesting that execution-related EEG signals may provide stronger or more consistent lateralization cues at this scale.\n",
    "\n",
    "---\n",
    "\n",
    "### Performance by Run\n",
    "\n",
    "| Run | Task Type | Accuracy | Samples |\n",
    "|----|----------|----------|---------|\n",
    "| 3  | Real      | 78.3% | 180 |\n",
    "| 4  | Imagined  | 79.4% | 180 |\n",
    "| 7  | Real      | 81.1% | 180 |\n",
    "| 8  | Imagined  | 68.9% | 180 |\n",
    "| 11 | Real      | 78.3% | 180 |\n",
    "| 12 | Imagined  | 77.8% | 180 |\n",
    "\n",
    "- **Run 7 (real)** yields the strongest performance.\n",
    "- **Run 8 (imagined)** is consistently the most challenging.\n",
    "- Imagined runs show **higher variability**, while real runs are more stable.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- A pretrained **LaBraM** model can be effectively fine-tuned on EEGMMIDB for **left vs right hand decoding**.\n",
    "- The model **generalizes across imagined and real motor tasks**, even when these conditions are not explicitly modeled during training.\n",
    "- Execution (real movement) tends to be slightly easier to decode than imagery at scale.\n",
    "- Performance differences across runs highlight **run-specific signal quality and task difficulty**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
