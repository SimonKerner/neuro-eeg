{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6a7264",
   "metadata": {},
   "source": [
    "# EEGMMIDB â€” Data Exploration & NeuroGPT Classification\n",
    "\n",
    "Goal:\n",
    "- Load the EEGMMIDB motor movement / imagery dataset\n",
    "- Explore signals and labels\n",
    "- Classification with NeuroGPT usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b813e51b-f23c-4999-9a39-bec3cbbe821f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /opt/micromamba/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/micromamba/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: tf-keras in /opt/micromamba/lib/python3.11/site-packages (2.20.1)\n",
      "Requirement already satisfied: transformers[torch] in /opt/micromamba/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: decorator in /opt/micromamba/lib/python3.11/site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/micromamba/lib/python3.11/site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/micromamba/lib/python3.11/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.8 in /opt/micromamba/lib/python3.11/site-packages (from mne) (3.9.4)\n",
      "Requirement already satisfied: numpy<3,>=1.26 in /opt/micromamba/lib/python3.11/site-packages (from mne) (2.4.1)\n",
      "Requirement already satisfied: packaging in /opt/micromamba/lib/python3.11/site-packages (from mne) (26.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.11 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.16.2)\n",
      "Requirement already satisfied: tqdm in /opt/micromamba/lib/python3.11/site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2026.1.15)\n",
      "Requirement already satisfied: requests in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2026.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (1.2.0)\n",
      "Requirement already satisfied: psutil in /opt/micromamba/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/micromamba/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.6.2)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /opt/micromamba/lib/python3.11/site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.31.1)\n",
      "Requirement already satisfied: setuptools in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.62.2)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (2026.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
      "Requirement already satisfied: pillow in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/micromamba/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.1.0)\n",
      "Requirement already satisfied: namex in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/micromamba/lib/python3.11/site-packages (from pooch>=1.5->mne) (4.4.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/micromamba/lib/python3.11/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from sympy>=1.13.3->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/micromamba/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/micromamba/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne \"transformers[torch]\" \"accelerate>=0.26.0\" tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e6ab2-f2b6-4073-bbcc-9e25ed302134",
   "metadata": {},
   "source": [
    "## PhysioNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb62aefd-3ec5-4a4d-93cd-37ca32a82f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/jovyan/neuro-eeg\n",
      "Data path: /home/jovyan/neuro-eeg/data/physionet.org/files/eegmmidb/1.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SRC_PATH = PROJECT_ROOT / \"src\"\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"physionet.org\" / \"files\" / \"eegmmidb\" / \"1.0.0\"\n",
    "\n",
    "sys.path.append(str(SRC_PATH))\n",
    "\n",
    "from src.dataloader import EEGMMIDBDataset\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Data path:\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c92f5272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "\n",
    "edf = DATA_PATH / \"S001\" / \"S001R03.edf\"\n",
    "raw = mne.io.read_raw_edf(edf, preload=False, verbose=False)\n",
    "\n",
    "print(raw.ch_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0c892",
   "metadata": {},
   "source": [
    "### Load Dataset for exploration\n",
    "\n",
    "Subject 1, motor execution + imagery, left/right hand\n",
    "\n",
    "Classes:\n",
    "- 0: Right imagined\n",
    "- 1: Right real\n",
    "- 2: Left imagined\n",
    "- 3: Left real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71a86bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Total extracted trials: 45\n"
     ]
    }
   ],
   "source": [
    "dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=[1],\n",
    "    runs=[4, 8, 12],\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "print(\"Total extracted trials:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dfadd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset-level class counts:\n",
      "Left Imagined  : 23\n",
      "Right Imagined : 22\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels = [dataset[i][\"labels\"].item() for i in range(len(dataset))]\n",
    "\n",
    "label_map = {\n",
    "    0: \"Left Imagined\",\n",
    "    1: \"Right Imagined\",\n",
    "}\n",
    "\n",
    "counts = Counter(labels)\n",
    "\n",
    "print(\"Dataset-level class counts:\")\n",
    "for k in sorted(label_map):\n",
    "    print(f\"{label_map[k]:<15}: {counts.get(k, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba6d0642-bca0-4a09-bba3-4012d8ea0086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "792e70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw EDF annotation summary (Subject 1):\n",
      "\n",
      "Run 4: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 8: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 12: {'T0': 1, 'T1': 1, 'T2': 1}\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from collections import defaultdict\n",
    "\n",
    "event_summary = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for run in [4, 8, 12]:\n",
    "    edf_path = DATA_PATH / \"S001\" / f\"S001R{run:02d}.edf\"\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "    \n",
    "    _, event_id = mne.events_from_annotations(raw, verbose=False)\n",
    "    \n",
    "    for label in event_id.keys():\n",
    "        event_code = label.split(\"/\")[-1]\n",
    "        event_summary[run][event_code] += 1\n",
    "\n",
    "print(\"Raw EDF annotation summary (Subject 1):\\n\")\n",
    "for run, events in event_summary.items():\n",
    "    print(f\"Run {run}: {dict(events)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd9439ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample-wise label sanity check (first 10 trials):\n",
      "\n",
      "Trial 00 -> Class 1: Right Imagined\n",
      "Trial 01 -> Class 0: Left Imagined\n",
      "Trial 02 -> Class 0: Left Imagined\n",
      "Trial 03 -> Class 1: Right Imagined\n",
      "Trial 04 -> Class 1: Right Imagined\n",
      "Trial 05 -> Class 0: Left Imagined\n",
      "Trial 06 -> Class 1: Right Imagined\n",
      "Trial 07 -> Class 0: Left Imagined\n",
      "Trial 08 -> Class 1: Right Imagined\n",
      "Trial 09 -> Class 0: Left Imagined\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample-wise label sanity check (first 10 trials):\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    sample = dataset[i]\n",
    "    label = sample[\"labels\"].item()\n",
    "    print(f\"Trial {i:02d} -> Class {label}: {label_map[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6678bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean signal energy per class:\n",
      "Left Imagined  : 0.8801\n",
      "Right Imagined : 0.8821\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "energy_by_class = defaultdict(list)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    label = sample[\"labels\"].item()\n",
    "    energy = sample[\"inputs\"].pow(2).mean().item()\n",
    "    energy_by_class[label].append(energy)\n",
    "\n",
    "print(\"Mean signal energy per class:\")\n",
    "for k in sorted(label_map):\n",
    "    print(f\"{label_map[k]:<15}: {np.mean(energy_by_class[k]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88cd98",
   "metadata": {},
   "source": [
    "### NeuroGPT Teaser\n",
    "\n",
    "Each trial is already:\n",
    "- 22-channel (NeuroGPT format)\n",
    "- Normalized\n",
    "- Fixed-length\n",
    "- Labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93a9b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 22, 500])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "batch = dataset[0]\n",
    "print(batch[\"inputs\"].shape)\n",
    "print(batch[\"labels\"].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3daa241",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed89fab4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0c63cc",
   "metadata": {},
   "source": [
    "### Loading the train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8386c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108]\n",
      "MI_ME runs: [4, 8, 12]\n"
     ]
    }
   ],
   "source": [
    "all_subjects = list(range(1, 109))  # subject range\n",
    "print(\"Subjects:\", all_subjects)\n",
    "\n",
    "MI_ME_RUNS = [4, 8, 12]\n",
    "print(\"MI_ME runs:\", MI_ME_RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2db9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folds\n",
    "\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "\n",
    "for i in range(len(all_subjects) // 2):\n",
    "    test_subjects = all_subjects[i*2 : i*2+2]\n",
    "    train_subjects = all_subjects[:i*2] + all_subjects[i*2+2:]\n",
    "\n",
    "    train_folds.append(train_subjects)\n",
    "    test_folds.append(test_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9fb3485-15d1-4ac6-a339-e28fd8ef63a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/src/dataloader.py:88: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader.py:88: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/src/dataloader.py:88: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "from src.dataloader import EEGMMIDBDataset\n",
    "\n",
    "\n",
    "train_dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=train_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "test_dataset_EEG = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=test_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "907856ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test trials : 90\n",
      "Input shape: torch.Size([2, 22, 500])\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "#print(\"Train trials:\", len(train_dataset))\n",
    "print(\"Test trials :\", len(test_dataset_EEG))\n",
    "\n",
    "batch = test_dataset_EEG[0]\n",
    "print(\"Input shape:\", batch[\"inputs\"].shape)   # (22, T)\n",
    "print(\"Label:\", batch[\"labels\"].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "896333a7-1c1e-49cb-a55f-cbf379ba6591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset channel order:\n",
      "0 Fz\n",
      "1 Fc3\n",
      "2 Fc1\n",
      "3 Fcz\n",
      "4 Fc2\n",
      "5 Fc4\n",
      "6 C5\n",
      "7 C3\n",
      "8 C1\n",
      "9 Cz\n",
      "10 C2\n",
      "11 C4\n",
      "12 C6\n",
      "13 Cp3\n",
      "14 Cp1\n",
      "15 Cpz\n",
      "16 Cp2\n",
      "17 Cp4\n",
      "18 P1\n",
      "19 Pz\n",
      "20 P2\n",
      "21 Poz\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset channel order:\")\n",
    "for i, ch in enumerate(test_dataset_EEG.ch_names):\n",
    "    print(i, ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "127dbc85-ad86-4c04-bbf7-39564e19af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution: Counter({0: 2410, 1: 2372})\n",
      "Test Label Distribution: Counter({0: 46, 1: 44})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Check Training Labels\n",
    "train_counts = Counter(train_dataset.labels)\n",
    "print(f\"Training Label Distribution: {train_counts}\")\n",
    "# Expected: {0: count_left, 1: count_right}\n",
    "\n",
    "# Check Test Labels\n",
    "test_counts = Counter(test_dataset_EEG.labels)\n",
    "print(f\"Test Label Distribution: {test_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62bd51-b77f-46cb-a25f-5f70163658a7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "400a4c8d-334f-46a9-9136-0aa3d348c913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 16:16:50.445758: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "home = os.environ[\"HOME\"]\n",
    "python_imports = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder\"\n",
    "cache_root = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/\"\n",
    "sys.path.append(python_imports)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys \n",
    "sys.path.insert(0,os.path.join(python_imports,'NeuroGPT_mini/') )\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, f1_score\n",
    "import random\n",
    "import json\n",
    "\n",
    "### Import related to Transformer model (from files located in /NeuroGPT directory)\n",
    "\n",
    "from encoder.conformer_braindecode import EEGConformer\n",
    "from decoder.make_decoder import make_decoder\n",
    "from embedder.make import make_embedder\n",
    "from trainer.make import make_trainer\n",
    "from trainer.base import Trainer\n",
    "from decoder.unembedder import make_unembedder\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "with open(os.path.join(python_imports,\"NeuroGPT_mini/config.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91e06753-7d49-45a0-82f8-834e8dc60846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = {\"dst_data_path\" : os.path.join(python_imports, \"bciiv2a_eeg_npz/\"),\n",
    "         \"pretrained_model\" : os.path.join(python_imports, \"NeuroGPT_mini/pytorch_model.bin\"), \n",
    "         \"log_dir\" :os.path.join(python_imports,\"training_logs/\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7eccc5d8-b47f-4bf4-b2c3-db7f885ef11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Create Model object from embedder, decoder,\n",
    "    and unembedder (if not None).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    embedder: src.embedder.make_embedder\n",
    "        Instance of embedder class.\n",
    "    decoder: src.decoder.make_decoder\n",
    "        Instance of decoder class.\n",
    "    unembedder: src.unembedder.make_unembedder\n",
    "        Instance of unembedder class.\n",
    "        Only added to model if not None.\n",
    "\n",
    "    Methods\n",
    "    ----\n",
    "    forward(batch: Dict[str, torch.tensor])\n",
    "        Forward pass of model.\n",
    "    prep_batch(batch: Dict[str, torch.tensor])\n",
    "        Prepare batch for forward pass.\n",
    "    compute_loss(batch: Dict[str, torch.tensor])\n",
    "        Compute training loss.\n",
    "    from_pretrained(pretrained_path: str)\n",
    "        Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        embedder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,\n",
    "        unembedder: torch.nn.Module = None\n",
    "        ) -> torch.nn.Module:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.name = f'Embedder-{embedder.name}_Decoder-{decoder.name}'\n",
    "        self.encoder = encoder\n",
    "        self.embedder = embedder\n",
    "        self.decoder = decoder\n",
    "        self.unembedder = unembedder\n",
    "        self.is_decoding_mode = False\n",
    "        self.ft_only_encoder = False\n",
    "\n",
    "    def from_pretrained(\n",
    "        self,\n",
    "        pretrained_path: str\n",
    "        ) -> None:\n",
    "        \"\"\"Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f'Loading pretrained model from {pretrained_path}'\n",
    "        )\n",
    "\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            pretrained = torch.load(pretrained_path)\n",
    "\n",
    "        else:\n",
    "            pretrained = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
    "        \n",
    "        for k in self.state_dict():\n",
    "            \n",
    "            if k in pretrained:\n",
    "                assert pretrained[k].shape == self.state_dict()[k].shape,\\\n",
    "                    f'{k} shape mismatch between pretrained model and current model '+\\\n",
    "                    f'{pretrained[k].shape} vs {self.state_dict()[k].shape}'\n",
    "        \n",
    "        for k in pretrained:     \n",
    "            if k not in self.state_dict():\n",
    "                warnings.warn(\n",
    "                    f'Warning: /!\\ Skipping {k} from {pretrained_path} '\\\n",
    "                    'because it is not part of the current model'\n",
    "                )\n",
    "\n",
    "        # we set strict=False, because we can be sure\n",
    "        # that all relevant keys are in pretrained\n",
    "        self.load_state_dict(pretrained, strict=False)\n",
    "        \n",
    "    def switch_ft_mode(self, ft_encoder_only=False):\n",
    "        self.ft_only_encoder = ft_encoder_only\n",
    "\n",
    "    def switch_decoding_mode(\n",
    "        self,\n",
    "        is_decoding_mode: bool = False,\n",
    "        num_decoding_classes: int = None\n",
    "        ) -> None:\n",
    "        \"\"\"Switch model to decoding model or back to training mode.\n",
    "        Necessary to adapt pre-trained models to downstream\n",
    "        decoding tasks.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        is_decoding_mode: bool\n",
    "            Whether to switch to decoding mode or not.\n",
    "        num_decoding_classes: int\n",
    "            Number of classes to use for decoding.    \n",
    "        \"\"\"\n",
    "        self.is_decoding_mode = is_decoding_mode\n",
    "        \n",
    "        self.embedder.switch_decoding_mode(is_decoding_mode=is_decoding_mode)\n",
    "        self.decoder.switch_decoding_mode(\n",
    "            is_decoding_mode=is_decoding_mode,\n",
    "            num_decoding_classes=num_decoding_classes\n",
    "        )\n",
    "\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        return_outputs: bool = False\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"\n",
    "        Compute training loss, based on \n",
    "        embedder's training-style.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        return_outputs: bool\n",
    "            Whether to return outputs of forward pass\n",
    "            or not. If False, only loss is returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        losses: Dict[str, torch.tensor]\n",
    "            Training losses.\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        \"\"\"\n",
    "        (outputs, batch) = self.forward(\n",
    "            batch=batch,\n",
    "            return_batch=True\n",
    "        )\n",
    "        losses = self.embedder.loss(\n",
    "            batch=batch,\n",
    "            outputs=outputs\n",
    "        )\n",
    "\n",
    "        return (losses, outputs) if return_outputs else losses\n",
    "\n",
    "    def prep_batch(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor]\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"Prepare input batch for forward pass.\n",
    "        Calls src.embedder.prep_batch.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        \"\"\"\n",
    "        return self.embedder.prep_batch(batch=dict(batch))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        prep_batch: bool = True,\n",
    "        return_batch: bool = False\n",
    "        ) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of model.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        prep_batch: bool\n",
    "            Whether to prep batch for forward pass\n",
    "            by calling self.embedder.prep_batch\n",
    "        return_batch: bool\n",
    "            Whether to return batch after forward pass\n",
    "            or not. If False, only outputs of forward pass\n",
    "            are returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as returned by prep_batch, \n",
    "            if prep_batch is True)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.encoder is not None:\n",
    "            #before prep_batch masking and things, we need to first let the splitted chunks of raw input through the encoder\n",
    "            features = self.encoder(batch['inputs'])\n",
    "            #attempt for trying fine-tune only the encoder, but the encoder cannot combine information across chunks.\n",
    "            if self.is_decoding_mode and self.ft_only_encoder:\n",
    "                outputs={'outputs': features, 'decoding_logits': features}\n",
    "                return (outputs, batch) if return_batch else outputs\n",
    "\n",
    "            b, f1, f2 = features.size()\n",
    "            nchunks = batch['inputs'].size()[1]\n",
    "            batch['inputs'] = features.view(b//nchunks, nchunks, f1*f2)\n",
    "        \n",
    "        if prep_batch:\n",
    "            if len(batch['inputs'].size()) > 3:\n",
    "                bsize, chunk, chann, time = batch['inputs'].size() \n",
    "                batch['inputs'] = batch['inputs'].view(bsize, chunk, chann*time)\n",
    "            batch = self.prep_batch(batch=batch)\n",
    "            # batch['inputs_embeds'] = batch['inputs_embeds'].view(bsize, chunk, chann, time)\n",
    "            # print(\"preparing batch\")\n",
    "        else:\n",
    "            assert 'inputs_embeds' in batch, 'inputs_embeds not in batch'\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        batch['inputs_embeds'] = self.embedder(batch=batch)\n",
    "        outputs = self.decoder(batch=batch)\n",
    "        \n",
    "        if self.unembedder is not None and not self.is_decoding_mode:\n",
    "            outputs['outputs'] = self.unembedder(inputs=outputs['outputs'])['outputs']\n",
    "\n",
    "        return (outputs, batch) if return_batch else outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f95ca59f-4ef1-4d67-a0ee-a965fd0cda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model_config) : \n",
    "# Generate the model\n",
    "    \n",
    "    \n",
    "    ## Encoder\n",
    "    \n",
    "    if model_config[\"use_encoder\"] == True:\n",
    "        \n",
    "        chann_coords = None\n",
    "        encoder = EEGConformer(n_outputs=model_config[\"num_decoding_classes\"], n_chans=22, n_times=model_config['chunk_len'], ch_pos=chann_coords, is_decoding_mode=model_config[\"ft_only_encoder\"])\n",
    "        #calculates the output dimension of the encoder, which is the output of transformer layer.\n",
    "        model_config[\"parcellation_dim\"] = ((model_config['chunk_len'] - model_config['filter_time_length'] + 1 - model_config['pool_time_length']) // model_config['stride_avg_pool'] + 1) * model_config['n_filters_time']\n",
    "\n",
    "    else:\n",
    "        encoder = None\n",
    "        model_config[\"parcellation_dim\"] = model_config[\"chunk_len\"] * 22\n",
    "    \n",
    "    ## Embedder\n",
    "    \n",
    "    embedder = make_embedder(\n",
    "        training_style=model_config[\"training_style\"],\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        in_dim=model_config[\"parcellation_dim\"], # flattened, channel x chunk length\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers_embedding_model\"],\n",
    "        dropout=model_config[\"dropout\"],\n",
    "        n_positions=model_config[\"n_positions\"]\n",
    "    )\n",
    "    \n",
    "    ## Decoder\n",
    "    decoder = make_decoder(\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers\"],\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_attention_heads=model_config[\"num_attention_heads\"],\n",
    "        n_positions=model_config[\"n_positions\"],\n",
    "        intermediate_dim_factor=model_config[\"intermediate_dim_factor\"],\n",
    "        hidden_activation=model_config[\"hidden_activation\"],\n",
    "        dropout=model_config[\"dropout\"]\n",
    "    )\n",
    "   \n",
    "    \n",
    "    if model_config[\"embedding_dim\"] != model_config[\"parcellation_dim\"]:\n",
    "        unembedder = make_unembedder(\n",
    "            embed_dim=model_config[\"embedding_dim\"],\n",
    "            num_hidden_layers=model_config[\"num_hidden_layers_unembedding_model\"],\n",
    "            out_dim=model_config[\"parcellation_dim\"],\n",
    "            dropout=model_config[\"dropout\"],\n",
    "        )\n",
    "    else:\n",
    "        print(\"No Embedder and Unembedder!\")\n",
    "        unembedder = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(\n",
    "        encoder=encoder,\n",
    "        embedder=embedder,\n",
    "        decoder=decoder,\n",
    "        unembedder=unembedder\n",
    "    )\n",
    "    \n",
    "    if model_config[\"ft_only_encoder\"]:\n",
    "        model.switch_ft_mode(ft_encoder_only=True)\n",
    "    \n",
    "    if model_config[\"training_style\"] == 'decoding':\n",
    "        model.switch_decoding_mode(\n",
    "            is_decoding_mode=True,\n",
    "            num_decoding_classes=model_config[\"num_decoding_classes\"]\n",
    "        )\n",
    "    \n",
    "    if model_config[\"pretrained_model\"] is not None:\n",
    "        model.from_pretrained(model_config[\"pretrained_model\"])\n",
    "    \n",
    "    if model_config[\"freeze_embedder\"]:\n",
    "        for param in model.embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_decoder\"]:\n",
    "\n",
    "        ## TO DO : freeze the parameters of the decoder module :\n",
    "        for param in model.decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    if model_config[\"freeze_encoder\"]:\n",
    "        for name, param in model.encoder.named_parameters():\n",
    "            if 'fc.' in name \\\n",
    "            or 'final_layer' in name:\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        print('Frozen Encoder : Only the two last layers will be trained')\n",
    "    \n",
    "    if 'freeze_decoder_without_pooler_heads' in model_config \\\n",
    "        and model_config[\"freeze_decoder_without_pooler_heads\"]:\n",
    "        for name, param in model.decoder.named_parameters():\n",
    "            if 'pooler_layer' in name \\\n",
    "            or 'decoding_head' in name \\\n",
    "            or 'is_next_head' in name:\n",
    "    \n",
    "\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_unembedder\"] and unembedder is not None:\n",
    "        for param in model.unembedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69ef0c94-d3b8-442d-b51c-43499d3374a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model_config = config\n",
    "\n",
    "## Some important parameters in the architecture of the model \n",
    "\n",
    "model_config['pretrained_model'] = config_path['pretrained_model'] # Path to the file containing pretrained weights of the model, if model_config['pretrained_model'] = None the model is not pretrained\n",
    "model_config['embedding_dim'] = 1024 # Dimension of the latent representations in the model\n",
    "model_config['num_hidden_layers_embedding_model']= 1 # Number of hidden layers in the GPT model \n",
    "model_config['num_hidden_layers_unembedding_model']= 1 # Number of hidden layers on the unembedding module \n",
    "model_config['num_hidden_layers']= 6  #Number of hidden layers in the encoder module\n",
    "model_config['filter_time_length']= 25 #Size of the kernel of the temporal convolution layer \n",
    "model_config['stride_avg_pool']= 15  # Stride size used in the average-pooling operation\n",
    "model_config[\"freeze_encoder\"] = False # Whether to freeze the encoder (True = no training on encoder parameters, only the classification layer)\n",
    "\n",
    "\n",
    "model = make_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3dde66a-9c48-418e-a02e-aac3b9628a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = config\n",
    "\n",
    "# Some important paramerter to build up the training stategy\n",
    "\n",
    "trainer_config['model_init'] = make_model # Function used to instanciate a model\n",
    "trainer_config['run_name'] = 'Finetunning_1' # Name of the run to save logs in a directory \n",
    "trainer_config['train_dataset'] = train_dataset \n",
    "trainer_config['validation_dataset'] = test_dataset_EEG\n",
    "trainer_config['output_dir'] = os.path.join(config_path['log_dir'], trainer_config['run_name']) # Where to save training logs\n",
    "\n",
    "trainer_config['training_steps'] = 3000 # Number of training steps\n",
    "trainer_config['validation_steps'] = 500 # Number of validation steps\n",
    "# Whether to freeze the encoder (True = no training on encoder parameters)\n",
    "trainer_config['model_save_steps'] = config[\"training_steps\"]*2\n",
    "trainer_config['log_every_n_steps'] = 1000\n",
    "trainer_config['eval_every_n_steps'] = 500\n",
    "trainer_config['warmup_ratio'] = 0.01\n",
    "trainer_config['optim'] = \"adamw_torch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d32eed5-024f-42a0-86d7-650879f8cecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer = make_trainer(model_init=lambda: make_model(model_config), config = trainer_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b852a3c-ba46-4a31-8b6b-1ef86f99d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n",
      "Loading pretrained model from /home/jovyan/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/NeuroGPT_mini/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 02:37, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.364700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.338100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of the training ! \n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "print(\"End of the training ! \")\n",
    "save_path = os.path.join(config[\"log_dir\"], trainer_config['run_name'], 'model_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44f13504-c120-422a-ac44-300eae1bda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved to :  training_logs/Finetunning_1/model_final\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723de41-2592-4686-b460-9163b5466e23",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcf669eb-e7a1-4875-999e-5f5b3cd3656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, \n",
    "    cohen_kappa_score, \n",
    "    f1_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "def get_performance_from_trainer(trainer, test_dataset):\n",
    "    \"\"\"\n",
    "    This function takes as input a trainer that has already been trained \n",
    "    (So the the trainer.train() method must already been called on it)\n",
    "    And it returns the a dictionnary with the different performance metrics. \n",
    "    \"\"\"\n",
    "    test_prediction_ = trainer.predict(test_dataset)\n",
    "    test_preds = test_prediction_.predictions\n",
    "    test_labels = test_prediction_.label_ids\n",
    "    pred_label=np.argmax(test_preds, axis=1)\n",
    "\n",
    "    true_label = test_labels\n",
    "    pred_label = pred_label \n",
    "    balanced_acc = balanced_accuracy_score(true_label, pred_label)\n",
    "\n",
    "    kappa = cohen_kappa_score(true_label, pred_label)\n",
    "\n",
    "    weighted_f1 = f1_score(true_label, pred_label, average='weighted')\n",
    "\n",
    "    cm = confusion_matrix(true_label, pred_label)\n",
    "    \n",
    "    return {\n",
    "        'Balanced Accuracy': balanced_acc,\n",
    "        'Cohen s Kappa': kappa, \n",
    "        'Weighted F1-score': weighted_f1,\n",
    "        'Confusion Matrix': cm \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "507fddca-b99d-44d8-be18-2c79fbf95032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Balanced Accuracy': np.float64(0.7682806324110671), 'Cohen s Kappa': np.float64(0.534711964549483), 'Weighted F1-score': 0.7656553147574818, 'Confusion Matrix': array([[32, 14],\n",
      "       [ 7, 37]])}\n"
     ]
    }
   ],
   "source": [
    "print(get_performance_from_trainer(trainer, test_dataset_EEG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7547375-e4eb-407c-8dec-c63d16eea6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.7683\n",
      "Cohen's Kappa: 0.5347\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1. Get metrics from your existing function\n",
    "metrics = get_performance_from_trainer(trainer, test_dataset_EEG)\n",
    "cm = metrics['Confusion Matrix']\n",
    "\n",
    "# 2. Define the class labels (since you filtered for Left/Right only)\n",
    "class_names = ['Left Hand', 'Right Hand']\n",
    "\n",
    "# 3. Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "\n",
    "plt.title('Confusion Matrix: Motor Imagery (Left vs. Right)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Print the other metrics for context\n",
    "print(f\"Balanced Accuracy: {metrics['Balanced Accuracy']:.4f}\")\n",
    "print(f\"Cohen's Kappa: {metrics['Cohen s Kappa']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a486c8-fde2-41d0-9a2a-e1090878357c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neuro EEG",
   "language": "python",
   "name": "neuro-eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
