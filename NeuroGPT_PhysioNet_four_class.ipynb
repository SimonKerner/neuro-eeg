{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6a7264",
   "metadata": {},
   "source": [
    "# EEGMMIDB â€” Data Exploration & NeuroGPT Classification\n",
    "\n",
    "Goal:\n",
    "- Load the EEGMMIDB motor movement / imagery dataset\n",
    "- Explore signals and labels\n",
    "- Classification with NeuroGPT usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b813e51b-f23c-4999-9a39-bec3cbbe821f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /opt/micromamba/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/micromamba/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: tf-keras in /opt/micromamba/lib/python3.11/site-packages (2.20.1)\n",
      "Requirement already satisfied: transformers[torch] in /opt/micromamba/lib/python3.11/site-packages (4.56.2)\n",
      "Requirement already satisfied: decorator in /opt/micromamba/lib/python3.11/site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/micromamba/lib/python3.11/site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/micromamba/lib/python3.11/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.8 in /opt/micromamba/lib/python3.11/site-packages (from mne) (3.10.6)\n",
      "Requirement already satisfied: numpy<3,>=1.26 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/micromamba/lib/python3.11/site-packages (from mne) (25.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.11 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /opt/micromamba/lib/python3.11/site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.35.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: torch>=2.2 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.1.10)\n",
      "Requirement already satisfied: psutil in /opt/micromamba/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.1.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /opt/micromamba/lib/python3.11/site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.31.1)\n",
      "Requirement already satisfied: setuptools in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.62.2)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
      "Requirement already satisfied: pillow in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/micromamba/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.1.0)\n",
      "Requirement already satisfied: namex in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/micromamba/lib/python3.11/site-packages (from pooch>=1.5->mne) (4.4.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/micromamba/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/micromamba/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne \"transformers[torch]\" \"accelerate>=0.26.0\" tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e6ab2-f2b6-4073-bbcc-9e25ed302134",
   "metadata": {},
   "source": [
    "## PhysioNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb62aefd-3ec5-4a4d-93cd-37ca32a82f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/jovyan/neuro-eeg\n",
      "Data path: /home/jovyan/neuro-eeg/data/physionet.org/files/eegmmidb/1.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SRC_PATH = PROJECT_ROOT / \"src\"\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"physionet.org\" / \"files\" / \"eegmmidb\" / \"1.0.0\"\n",
    "\n",
    "sys.path.append(str(SRC_PATH))\n",
    "\n",
    "from src.dataloader_simon import EEGMMIDBDataset\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Data path:\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92f5272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "\n",
    "edf = DATA_PATH / \"S001\" / \"S001R03.edf\"\n",
    "raw = mne.io.read_raw_edf(edf, preload=False, verbose=False)\n",
    "\n",
    "print(raw.ch_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0c892",
   "metadata": {},
   "source": [
    "### Load Dataset for exploration\n",
    "\n",
    "Subject 1, motor execution + imagery, left/right hand\n",
    "\n",
    "Classes:\n",
    "- 0: Right imagined\n",
    "- 1: Right real\n",
    "- 2: Left imagined\n",
    "- 3: Left real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a86bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted trials: 90\n"
     ]
    }
   ],
   "source": [
    "dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=[1],\n",
    "    runs=[3, 4, 7, 8, 11, 12],\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "print(\"Total extracted trials:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfadd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset-level class counts:\n",
      "Right imagined : 22\n",
      "Right real     : 22\n",
      "Left imagined  : 23\n",
      "Left real      : 23\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels = [dataset[i][\"labels\"].item() for i in range(len(dataset))]\n",
    "\n",
    "label_map = {\n",
    "    0: \"Right imagined\",\n",
    "    1: \"Right real\",\n",
    "    2: \"Left imagined\",\n",
    "    3: \"Left real\"\n",
    "}\n",
    "\n",
    "counts = Counter(labels)\n",
    "\n",
    "print(\"Dataset-level class counts:\")\n",
    "for k in sorted(label_map):\n",
    "    print(f\"{label_map[k]:<15}: {counts.get(k, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6d0642-bca0-4a09-bba3-4012d8ea0086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 1, 3, 3, 1, 3, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 3, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 1, 3, 3, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 3, 1, 1, 3, 1, 3, 3, 1, 1, 3, 3, 1, 1, 3, 1, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792e70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw EDF annotation summary (Subject 1):\n",
      "\n",
      "Run 3: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 4: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 7: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 8: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 11: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 12: {'T0': 1, 'T1': 1, 'T2': 1}\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from collections import defaultdict\n",
    "\n",
    "event_summary = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for run in [3,4, 7, 8,11, 12]:\n",
    "    edf_path = DATA_PATH / \"S001\" / f\"S001R{run:02d}.edf\"\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "    \n",
    "    _, event_id = mne.events_from_annotations(raw, verbose=False)\n",
    "    \n",
    "    for label in event_id.keys():\n",
    "        event_code = label.split(\"/\")[-1]\n",
    "        event_summary[run][event_code] += 1\n",
    "\n",
    "print(\"Raw EDF annotation summary (Subject 1):\\n\")\n",
    "for run, events in event_summary.items():\n",
    "    print(f\"Run {run}: {dict(events)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9439ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample-wise label sanity check (first 10 trials):\n",
      "\n",
      "Trial 00 -> Class 1: Right real\n",
      "Trial 01 -> Class 3: Left real\n",
      "Trial 02 -> Class 3: Left real\n",
      "Trial 03 -> Class 1: Right real\n",
      "Trial 04 -> Class 1: Right real\n",
      "Trial 05 -> Class 3: Left real\n",
      "Trial 06 -> Class 3: Left real\n",
      "Trial 07 -> Class 1: Right real\n",
      "Trial 08 -> Class 3: Left real\n",
      "Trial 09 -> Class 1: Right real\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample-wise label sanity check (first 10 trials):\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    sample = dataset[i]\n",
    "    label = sample[\"labels\"].item()\n",
    "    print(f\"Trial {i:02d} -> Class {label}: {label_map[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6678bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean signal energy per class:\n",
      "Right imagined : 0.9171\n",
      "Right real     : 0.9238\n",
      "Left imagined  : 0.9144\n",
      "Left real      : 0.9249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "energy_by_class = defaultdict(list)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    label = sample[\"labels\"].item()\n",
    "    energy = sample[\"inputs\"].pow(2).mean().item()\n",
    "    energy_by_class[label].append(energy)\n",
    "\n",
    "print(\"Mean signal energy per class:\")\n",
    "for k in sorted(label_map):\n",
    "    print(f\"{label_map[k]:<15}: {np.mean(energy_by_class[k]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88cd98",
   "metadata": {},
   "source": [
    "### NeuroGPT Teaser\n",
    "\n",
    "Each trial is already:\n",
    "- 22-channel (NeuroGPT format)\n",
    "- Normalized\n",
    "- Fixed-length\n",
    "- Labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a9b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 22, 500])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "batch = dataset[0]\n",
    "print(batch[\"inputs\"].shape)\n",
    "print(batch[\"labels\"].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3daa241",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed89fab4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0c63cc",
   "metadata": {},
   "source": [
    "### Loading the train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8386c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108]\n",
      "MI_ME runs: [3, 4, 7, 8, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "all_subjects = list(range(1, 109))  # subject range\n",
    "print(\"Subjects:\", all_subjects)\n",
    "\n",
    "MI_ME_RUNS = [3,4, 7, 8,11, 12]\n",
    "print(\"MI_ME runs:\", MI_ME_RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2db9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folds\n",
    "all_subjects = list(range(1, 110)) # Example for PhysioNet (109 subjects)\n",
    "train_folds = []\n",
    "val_folds = []\n",
    "test_folds = []\n",
    "\n",
    "# Use a step of 2 to match your '2 subjects per test fold' logic\n",
    "for i in range(0, len(all_subjects) - 4, 2):\n",
    "    # 1. Test Set: 2 subjects\n",
    "    test_subjects = all_subjects[i : i+2]\n",
    "    \n",
    "    # 2. Validation Set: The next 2 subjects\n",
    "    val_subjects = all_subjects[i+2 : i+4]\n",
    "    \n",
    "    # 3. Training Set: Everything else\n",
    "    # We exclude the indices used for test and validation\n",
    "    train_subjects = [s for s in all_subjects if s not in test_subjects and s not in val_subjects]\n",
    "\n",
    "    train_folds.append(train_subjects)\n",
    "    val_folds.append(val_subjects)\n",
    "    test_folds.append(test_subjects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9fb3485-15d1-4ac6-a339-e28fd8ef63a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from src.dataloader_simon import EEGMMIDBDataset\n",
    "\n",
    "\n",
    "train_dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=train_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "test_dataset_EEG = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=test_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "val_dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=val_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907856ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train trials: 9484\n",
      "Validation trials : 180\n",
      "Test trials : 180\n",
      "Input shape: torch.Size([2, 22, 500])\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train trials:\", len(train_dataset))\n",
    "print(\"Validation trials :\", len(val_dataset))\n",
    "print(\"Test trials :\", len(test_dataset_EEG))\n",
    "\n",
    "batch = test_dataset_EEG[0]\n",
    "print(\"Input shape:\", batch[\"inputs\"].shape)   # (22, T)\n",
    "print(\"Label:\", batch[\"labels\"].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "127dbc85-ad86-4c04-bbf7-39564e19af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution: Counter({2: 2386, 3: 2384, 1: 2363, 0: 2351})\n",
      "Test Label Distribution: Counter({1: 47, 2: 47, 3: 43, 0: 43})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Check Training Labels\n",
    "train_counts = Counter(train_dataset.labels)\n",
    "print(f\"Training Label Distribution: {train_counts}\")\n",
    "# Expected: {0: count_left, 1: count_right}\n",
    "\n",
    "# Check Test Labels\n",
    "test_counts = Counter(test_dataset_EEG.labels)\n",
    "print(f\"Test Label Distribution: {test_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62bd51-b77f-46cb-a25f-5f70163658a7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "400a4c8d-334f-46a9-9136-0aa3d348c913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 19:52:15.231757: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "home = os.environ[\"HOME\"]\n",
    "python_imports = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder\"\n",
    "cache_root = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/\"\n",
    "sys.path.append(python_imports)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys \n",
    "sys.path.insert(0,os.path.join('NeuroGPT_mini/') )\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, f1_score\n",
    "import random\n",
    "import json\n",
    "\n",
    "### Import related to Transformer model (from files located in /NeuroGPT directory)\n",
    "\n",
    "from encoder.conformer_braindecode import EEGConformer\n",
    "from decoder.make_decoder import make_decoder\n",
    "from embedder.make import make_embedder\n",
    "from trainer.make import make_trainer\n",
    "from trainer.base import Trainer\n",
    "from decoder.unembedder import make_unembedder\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "with open(os.path.join(\"NeuroGPT_mini/config.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91e06753-7d49-45a0-82f8-834e8dc60846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = {\"dst_data_path\" : os.path.join(python_imports, \"bciiv2a_eeg_npz/\"),\n",
    "         \"pretrained_model\" : os.path.join(\"NeuroGPT_mini/pytorch_model.bin\"), \n",
    "         \"log_dir\" :os.path.join(\"training_logs/\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eccc5d8-b47f-4bf4-b2c3-db7f885ef11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Create Model object from embedder, decoder,\n",
    "    and unembedder (if not None).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    embedder: src.embedder.make_embedder\n",
    "        Instance of embedder class.\n",
    "    decoder: src.decoder.make_decoder\n",
    "        Instance of decoder class.\n",
    "    unembedder: src.unembedder.make_unembedder\n",
    "        Instance of unembedder class.\n",
    "        Only added to model if not None.\n",
    "\n",
    "    Methods\n",
    "    ----\n",
    "    forward(batch: Dict[str, torch.tensor])\n",
    "        Forward pass of model.\n",
    "    prep_batch(batch: Dict[str, torch.tensor])\n",
    "        Prepare batch for forward pass.\n",
    "    compute_loss(batch: Dict[str, torch.tensor])\n",
    "        Compute training loss.\n",
    "    from_pretrained(pretrained_path: str)\n",
    "        Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        embedder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,\n",
    "        unembedder: torch.nn.Module = None\n",
    "        ) -> torch.nn.Module:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.name = f'Embedder-{embedder.name}_Decoder-{decoder.name}'\n",
    "        self.encoder = encoder\n",
    "        self.embedder = embedder\n",
    "        self.decoder = decoder\n",
    "        self.unembedder = unembedder\n",
    "        self.is_decoding_mode = False\n",
    "        self.ft_only_encoder = False\n",
    "\n",
    "    def from_pretrained(\n",
    "        self,\n",
    "        pretrained_path: str\n",
    "        ) -> None:\n",
    "        \"\"\"Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f'Loading pretrained model from {pretrained_path}'\n",
    "        )\n",
    "\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            pretrained = torch.load(pretrained_path)\n",
    "\n",
    "        else:\n",
    "            pretrained = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
    "        \n",
    "        for k in self.state_dict():\n",
    "            \n",
    "            if k in pretrained:\n",
    "                assert pretrained[k].shape == self.state_dict()[k].shape,\\\n",
    "                    f'{k} shape mismatch between pretrained model and current model '+\\\n",
    "                    f'{pretrained[k].shape} vs {self.state_dict()[k].shape}'\n",
    "        \n",
    "        for k in pretrained:     \n",
    "            if k not in self.state_dict():\n",
    "                warnings.warn(\n",
    "                    f'Warning: /!\\ Skipping {k} from {pretrained_path} '\\\n",
    "                    'because it is not part of the current model'\n",
    "                )\n",
    "\n",
    "        # we set strict=False, because we can be sure\n",
    "        # that all relevant keys are in pretrained\n",
    "        self.load_state_dict(pretrained, strict=False)\n",
    "        \n",
    "    def switch_ft_mode(self, ft_encoder_only=False):\n",
    "        self.ft_only_encoder = ft_encoder_only\n",
    "\n",
    "    def switch_decoding_mode(\n",
    "        self,\n",
    "        is_decoding_mode: bool = False,\n",
    "        num_decoding_classes: int = None\n",
    "        ) -> None:\n",
    "        \"\"\"Switch model to decoding model or back to training mode.\n",
    "        Necessary to adapt pre-trained models to downstream\n",
    "        decoding tasks.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        is_decoding_mode: bool\n",
    "            Whether to switch to decoding mode or not.\n",
    "        num_decoding_classes: int\n",
    "            Number of classes to use for decoding.    \n",
    "        \"\"\"\n",
    "        self.is_decoding_mode = is_decoding_mode\n",
    "        \n",
    "        self.embedder.switch_decoding_mode(is_decoding_mode=is_decoding_mode)\n",
    "        self.decoder.switch_decoding_mode(\n",
    "            is_decoding_mode=is_decoding_mode,\n",
    "            num_decoding_classes=num_decoding_classes\n",
    "        )\n",
    "\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        return_outputs: bool = False\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"\n",
    "        Compute training loss, based on \n",
    "        embedder's training-style.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        return_outputs: bool\n",
    "            Whether to return outputs of forward pass\n",
    "            or not. If False, only loss is returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        losses: Dict[str, torch.tensor]\n",
    "            Training losses.\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        \"\"\"\n",
    "        (outputs, batch) = self.forward(\n",
    "            batch=batch,\n",
    "            return_batch=True\n",
    "        )\n",
    "        losses = self.embedder.loss(\n",
    "            batch=batch,\n",
    "            outputs=outputs\n",
    "        )\n",
    "\n",
    "        return (losses, outputs) if return_outputs else losses\n",
    "\n",
    "    def prep_batch(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor]\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"Prepare input batch for forward pass.\n",
    "        Calls src.embedder.prep_batch.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        \"\"\"\n",
    "        return self.embedder.prep_batch(batch=dict(batch))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        prep_batch: bool = True,\n",
    "        return_batch: bool = False\n",
    "        ) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of model.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        prep_batch: bool\n",
    "            Whether to prep batch for forward pass\n",
    "            by calling self.embedder.prep_batch\n",
    "        return_batch: bool\n",
    "            Whether to return batch after forward pass\n",
    "            or not. If False, only outputs of forward pass\n",
    "            are returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as returned by prep_batch, \n",
    "            if prep_batch is True)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.encoder is not None:\n",
    "            #before prep_batch masking and things, we need to first let the splitted chunks of raw input through the encoder\n",
    "            features = self.encoder(batch['inputs'])\n",
    "            #attempt for trying fine-tune only the encoder, but the encoder cannot combine information across chunks.\n",
    "            if self.is_decoding_mode and self.ft_only_encoder:\n",
    "                outputs={'outputs': features, 'decoding_logits': features}\n",
    "                return (outputs, batch) if return_batch else outputs\n",
    "\n",
    "            b, f1, f2 = features.size()\n",
    "            nchunks = batch['inputs'].size()[1]\n",
    "            batch['inputs'] = features.view(b//nchunks, nchunks, f1*f2)\n",
    "        \n",
    "        if prep_batch:\n",
    "            if len(batch['inputs'].size()) > 3:\n",
    "                bsize, chunk, chann, time = batch['inputs'].size() \n",
    "                batch['inputs'] = batch['inputs'].view(bsize, chunk, chann*time)\n",
    "            batch = self.prep_batch(batch=batch)\n",
    "            # batch['inputs_embeds'] = batch['inputs_embeds'].view(bsize, chunk, chann, time)\n",
    "            # print(\"preparing batch\")\n",
    "        else:\n",
    "            assert 'inputs_embeds' in batch, 'inputs_embeds not in batch'\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        batch['inputs_embeds'] = self.embedder(batch=batch)\n",
    "        outputs = self.decoder(batch=batch)\n",
    "        \n",
    "        if self.unembedder is not None and not self.is_decoding_mode:\n",
    "            outputs['outputs'] = self.unembedder(inputs=outputs['outputs'])['outputs']\n",
    "\n",
    "        return (outputs, batch) if return_batch else outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f95ca59f-4ef1-4d67-a0ee-a965fd0cda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model_config) : \n",
    "# Generate the model\n",
    "    \n",
    "    \n",
    "    ## Encoder\n",
    "    \n",
    "    if model_config[\"use_encoder\"] == True:\n",
    "        \n",
    "        chann_coords = None\n",
    "        encoder = EEGConformer(n_outputs=model_config[\"num_decoding_classes\"], n_chans=22, n_times=model_config['chunk_len'], ch_pos=chann_coords, is_decoding_mode=model_config[\"ft_only_encoder\"])\n",
    "        #calculates the output dimension of the encoder, which is the output of transformer layer.\n",
    "        model_config[\"parcellation_dim\"] = ((model_config['chunk_len'] - model_config['filter_time_length'] + 1 - model_config['pool_time_length']) // model_config['stride_avg_pool'] + 1) * model_config['n_filters_time']\n",
    "\n",
    "    else:\n",
    "        encoder = None\n",
    "        model_config[\"parcellation_dim\"] = model_config[\"chunk_len\"] * 22\n",
    "    \n",
    "    ## Embedder\n",
    "    \n",
    "    embedder = make_embedder(\n",
    "        training_style=model_config[\"training_style\"],\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        in_dim=model_config[\"parcellation_dim\"], # flattened, channel x chunk length\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers_embedding_model\"],\n",
    "        dropout=model_config[\"dropout\"],\n",
    "        n_positions=model_config[\"n_positions\"]\n",
    "    )\n",
    "    \n",
    "    ## Decoder\n",
    "    decoder = make_decoder(\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers\"],\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_attention_heads=model_config[\"num_attention_heads\"],\n",
    "        n_positions=model_config[\"n_positions\"],\n",
    "        intermediate_dim_factor=model_config[\"intermediate_dim_factor\"],\n",
    "        hidden_activation=model_config[\"hidden_activation\"],\n",
    "        dropout=model_config[\"dropout\"]\n",
    "    )\n",
    "   \n",
    "    \n",
    "    if model_config[\"embedding_dim\"] != model_config[\"parcellation_dim\"]:\n",
    "        unembedder = make_unembedder(\n",
    "            embed_dim=model_config[\"embedding_dim\"],\n",
    "            num_hidden_layers=model_config[\"num_hidden_layers_unembedding_model\"],\n",
    "            out_dim=model_config[\"parcellation_dim\"],\n",
    "            dropout=model_config[\"dropout\"],\n",
    "        )\n",
    "    else:\n",
    "        print(\"No Embedder and Unembedder!\")\n",
    "        unembedder = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(\n",
    "        encoder=encoder,\n",
    "        embedder=embedder,\n",
    "        decoder=decoder,\n",
    "        unembedder=unembedder\n",
    "    )\n",
    "    \n",
    "    if model_config[\"ft_only_encoder\"]:\n",
    "        model.switch_ft_mode(ft_encoder_only=True)\n",
    "    \n",
    "    if model_config[\"training_style\"] == 'decoding':\n",
    "        model.switch_decoding_mode(\n",
    "            is_decoding_mode=True,\n",
    "            num_decoding_classes=model_config[\"num_decoding_classes\"]\n",
    "        )\n",
    "    \n",
    "    if model_config[\"pretrained_model\"] is not None:\n",
    "        model.from_pretrained(model_config[\"pretrained_model\"])\n",
    "    \n",
    "    if model_config[\"freeze_embedder\"]:\n",
    "        for param in model.embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_decoder\"]:\n",
    "\n",
    "        ## TO DO : freeze the parameters of the decoder module :\n",
    "        for param in model.decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    if model_config[\"freeze_encoder\"]:\n",
    "        for name, param in model.encoder.named_parameters():\n",
    "            if 'fc.' in name \\\n",
    "            or 'final_layer' in name:\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        print('Frozen Encoder : Only the two last layers will be trained')\n",
    "    \n",
    "    if 'freeze_decoder_without_pooler_heads' in model_config \\\n",
    "        and model_config[\"freeze_decoder_without_pooler_heads\"]:\n",
    "        for name, param in model.decoder.named_parameters():\n",
    "            if 'pooler_layer' in name \\\n",
    "            or 'decoding_head' in name \\\n",
    "            or 'is_next_head' in name:\n",
    "    \n",
    "\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_unembedder\"] and unembedder is not None:\n",
    "        for param in model.unembedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69ef0c94-d3b8-442d-b51c-43499d3374a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model_config_PT_FT = config\n",
    "\n",
    "## Some important parameters in the architecture of the model \n",
    "\n",
    "model_config_PT_FT['pretrained_model'] = config_path['pretrained_model'] # Path to the file containing pretrained weights of the model, if model_config['pretrained_model'] = None the model is not pretrained\n",
    "model_config_PT_FT['embedding_dim'] = 1024 # Dimension of the latent representations in the model\n",
    "model_config_PT_FT['num_hidden_layers_embedding_model']= 1 # Number of hidden layers in the GPT model \n",
    "model_config_PT_FT['num_hidden_layers_unembedding_model']= 1 # Number of hidden layers on the unembedding module \n",
    "model_config_PT_FT['num_hidden_layers']= 6  #Number of hidden layers in the encoder module\n",
    "model_config_PT_FT['filter_time_length']= 25 #Size of the kernel of the temporal convolution layer \n",
    "model_config_PT_FT['stride_avg_pool']= 15  # Stride size used in the average-pooling operation\n",
    "model_config_PT_FT[\"freeze_encoder\"] = False # Whether to freeze the encoder (True = no training on encoder parameters, only the classification layer)\n",
    "model_config_PT_FT[\"learning_rate\"] = 0.001\n",
    "\n",
    "model = make_model(model_config_PT_FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3dde66a-9c48-418e-a02e-aac3b9628a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config_PT_FT = config\n",
    "\n",
    "# Some important paramerter to build up the training stategy\n",
    "\n",
    "trainer_config_PT_FT['model_init'] = make_model # Function used to instanciate a model\n",
    "trainer_config_PT_FT['run_name'] = 'Finetunning_PTFT' # Name of the run to save logs in a directory \n",
    "trainer_config_PT_FT['train_dataset'] = train_dataset \n",
    "trainer_config_PT_FT['validation_dataset'] = val_dataset\n",
    "trainer_config_PT_FT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_PT_FT['run_name']) # Where to save training logs\n",
    "\n",
    "trainer_config_PT_FT['training_steps'] = 3000 # Number of training steps\n",
    "trainer_config_PT_FT['validation_steps'] = 500 # Number of validation steps\n",
    "# Whether to freeze the encoder (True = no training on encoder parameters)\n",
    "trainer_config_PT_FT['model_save_steps'] = config[\"training_steps\"]*2\n",
    "trainer_config_PT_FT['log_every_n_steps'] = 1000\n",
    "trainer_config_PT_FT['eval_every_n_steps'] = 500\n",
    "trainer_config_PT_FT['warmup_ratio'] = 0.1\n",
    "trainer_config_PT_FT['optim'] = \"adamw_torch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d32eed5-024f-42a0-86d7-650879f8cecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer = make_trainer(model_init=lambda: make_model(model_config_PT_FT), config = trainer_config_PT_FT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b852a3c-ba46-4a31-8b6b-1ef86f99d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n",
      "Loading pretrained model from NeuroGPT_mini/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 01:35, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.994600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved to :  training_logs/checkpoint-3000\n",
      "End of the training ! \n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "print(\"End of the training ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44f13504-c120-422a-ac44-300eae1bda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved to :  training_logs/Finetunning_PTFT/model_final\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(config[\"log_dir\"], trainer_config_PT_FT['run_name'], 'model_final')\n",
    "trainer.save_model(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723de41-2592-4686-b460-9163b5466e23",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcf669eb-e7a1-4875-999e-5f5b3cd3656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, \n",
    "    cohen_kappa_score, \n",
    "    f1_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "def get_performance_from_trainer(trainer, test_dataset):\n",
    "    \"\"\"\n",
    "    This function takes as input a trainer that has already been trained \n",
    "    (So the the trainer.train() method must already been called on it)\n",
    "    And it returns the a dictionnary with the different performance metrics. \n",
    "    \"\"\"\n",
    "    test_prediction_ = trainer.predict(test_dataset)\n",
    "    test_preds = test_prediction_.predictions\n",
    "    test_labels = test_prediction_.label_ids\n",
    "    pred_label=np.argmax(test_preds, axis=1)\n",
    "\n",
    "    true_label = test_labels\n",
    "    pred_label = pred_label \n",
    "    balanced_acc = balanced_accuracy_score(true_label, pred_label)\n",
    "\n",
    "    kappa = cohen_kappa_score(true_label, pred_label)\n",
    "\n",
    "    weighted_f1 = f1_score(true_label, pred_label, average='weighted')\n",
    "\n",
    "    cm = confusion_matrix(true_label, pred_label)\n",
    "    \n",
    "    return {\n",
    "        'Balanced Accuracy': balanced_acc,\n",
    "        'Cohen s Kappa': kappa, \n",
    "        'Weighted F1-score': weighted_f1,\n",
    "        'Confusion Matrix': cm \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "507fddca-b99d-44d8-be18-2c79fbf95032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Balanced Accuracy': 0.4816922315685304, 'Cohen s Kappa': 0.30484798685291703, 'Weighted F1-score': 0.449925790206443, 'Confusion Matrix': array([[32,  6,  3,  2],\n",
      "       [27,  8,  9,  3],\n",
      "       [ 5,  3, 29, 10],\n",
      "       [ 4,  3, 19, 17]])}\n"
     ]
    }
   ],
   "source": [
    "perf_PT_FT = get_performance_from_trainer(trainer, test_dataset_EEG)\n",
    "print(get_performance_from_trainer(trainer, test_dataset_EEG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7547375-e4eb-407c-8dec-c63d16eea6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.4817\n",
      "Cohen's Kappa: 0.3048\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1. Get metrics from your existing function\n",
    "metrics = get_performance_from_trainer(trainer, test_dataset_EEG)\n",
    "cm = metrics['Confusion Matrix']\n",
    "\n",
    "# 2. Define the class labels (since you filtered for Left/Right only)\n",
    "class_names = ['Left Hand', 'Right Hand']\n",
    "\n",
    "# 3. Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "\n",
    "plt.title('Confusion Matrix: PhysioNet (Left vs. Right)')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Print the other metrics for context\n",
    "print(f\"Balanced Accuracy: {metrics['Balanced Accuracy']:.4f}\")\n",
    "print(f\"Cohen's Kappa: {metrics['Cohen s Kappa']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118fafe7-1e19-42a8-b084-94f178e4a0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30b4639d",
   "metadata": {},
   "source": [
    "# EEGMMIDB â€” Data Exploration & NeuroGPT Classification\n",
    "\n",
    "Goal:\n",
    "- Load the EEGMMIDB motor movement / imagery dataset\n",
    "- Explore signals and labels\n",
    "- Classification with NeuroGPT usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c243e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /opt/micromamba/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/micromamba/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: tf-keras in /opt/micromamba/lib/python3.11/site-packages (2.20.1)\n",
      "Requirement already satisfied: transformers[torch] in /opt/micromamba/lib/python3.11/site-packages (4.56.2)\n",
      "Requirement already satisfied: decorator in /opt/micromamba/lib/python3.11/site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/micromamba/lib/python3.11/site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/micromamba/lib/python3.11/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.8 in /opt/micromamba/lib/python3.11/site-packages (from mne) (3.10.6)\n",
      "Requirement already satisfied: numpy<3,>=1.26 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/micromamba/lib/python3.11/site-packages (from mne) (25.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.11 in /opt/micromamba/lib/python3.11/site-packages (from mne) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /opt/micromamba/lib/python3.11/site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.35.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: torch>=2.2 in /opt/micromamba/lib/python3.11/site-packages (from transformers[torch]) (2.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.1.10)\n",
      "Requirement already satisfied: psutil in /opt/micromamba/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.1.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /opt/micromamba/lib/python3.11/site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.31.1)\n",
      "Requirement already satisfied: setuptools in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.62.2)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/lib/python3.11/site-packages (from requests->transformers[torch]) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
      "Requirement already satisfied: pillow in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/micromamba/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.1.0)\n",
      "Requirement already satisfied: namex in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/micromamba/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/micromamba/lib/python3.11/site-packages (from matplotlib>=3.8->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/micromamba/lib/python3.11/site-packages (from pooch>=1.5->mne) (4.4.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/micromamba/lib/python3.11/site-packages (from torch>=2.2->transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/micromamba/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/micromamba/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/micromamba/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne \"transformers[torch]\" \"accelerate>=0.26.0\" tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7618d7",
   "metadata": {},
   "source": [
    "## PhysioNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5151be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/jovyan/neuro-eeg\n",
      "Data path: /home/jovyan/neuro-eeg/data/physionet.org/files/eegmmidb/1.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SRC_PATH = PROJECT_ROOT / \"src\"\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"physionet.org\" / \"files\" / \"eegmmidb\" / \"1.0.0\"\n",
    "\n",
    "sys.path.append(str(SRC_PATH))\n",
    "\n",
    "from src.dataloader_simon import EEGMMIDBDataset\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Data path:\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eea1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "\n",
    "edf = DATA_PATH / \"S001\" / \"S001R03.edf\"\n",
    "raw = mne.io.read_raw_edf(edf, preload=False, verbose=False)\n",
    "\n",
    "print(raw.ch_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1247844",
   "metadata": {},
   "source": [
    "### Load Dataset for exploration\n",
    "\n",
    "Subject 1, motor execution + imagery, left/right hand\n",
    "\n",
    "Classes:\n",
    "- 0: Right imagined\n",
    "- 1: Right real\n",
    "- 2: Left imagined\n",
    "- 3: Left real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7866ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted trials: 90\n"
     ]
    }
   ],
   "source": [
    "dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=[1],\n",
    "    runs=[3, 4, 7, 8, 11, 12],\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "print(\"Total extracted trials:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1706ba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset-level class counts:\n",
      "Right imagined : 22\n",
      "Right real     : 22\n",
      "Left imagined  : 23\n",
      "Left real      : 23\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels = [dataset[i][\"labels\"].item() for i in range(len(dataset))]\n",
    "\n",
    "label_map = {\n",
    "    0: \"Right imagined\",\n",
    "    1: \"Right real\",\n",
    "    2: \"Left imagined\",\n",
    "    3: \"Left real\"\n",
    "}\n",
    "\n",
    "counts = Counter(labels)\n",
    "\n",
    "print(\"Dataset-level class counts:\")\n",
    "for k in sorted(label_map):\n",
    "    print(f\"{label_map[k]:<15}: {counts.get(k, 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0480dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 1, 3, 3, 1, 3, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 3, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3, 1, 3, 3, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 3, 1, 1, 3, 1, 3, 3, 1, 1, 3, 3, 1, 1, 3, 1, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5ccdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw EDF annotation summary (Subject 1):\n",
      "\n",
      "Run 3: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 4: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 7: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 8: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 11: {'T0': 1, 'T1': 1, 'T2': 1}\n",
      "Run 12: {'T0': 1, 'T1': 1, 'T2': 1}\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from collections import defaultdict\n",
    "\n",
    "event_summary = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for run in [3,4, 7, 8,11, 12]:\n",
    "    edf_path = DATA_PATH / \"S001\" / f\"S001R{run:02d}.edf\"\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "    \n",
    "    _, event_id = mne.events_from_annotations(raw, verbose=False)\n",
    "    \n",
    "    for label in event_id.keys():\n",
    "        event_code = label.split(\"/\")[-1]\n",
    "        event_summary[run][event_code] += 1\n",
    "\n",
    "print(\"Raw EDF annotation summary (Subject 1):\\n\")\n",
    "for run, events in event_summary.items():\n",
    "    print(f\"Run {run}: {dict(events)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ab1f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample-wise label sanity check (first 10 trials):\n",
      "\n",
      "Trial 00 -> Class 1: Right real\n",
      "Trial 01 -> Class 3: Left real\n",
      "Trial 02 -> Class 3: Left real\n",
      "Trial 03 -> Class 1: Right real\n",
      "Trial 04 -> Class 1: Right real\n",
      "Trial 05 -> Class 3: Left real\n",
      "Trial 06 -> Class 3: Left real\n",
      "Trial 07 -> Class 1: Right real\n",
      "Trial 08 -> Class 3: Left real\n",
      "Trial 09 -> Class 1: Right real\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample-wise label sanity check (first 10 trials):\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    sample = dataset[i]\n",
    "    label = sample[\"labels\"].item()\n",
    "    print(f\"Trial {i:02d} -> Class {label}: {label_map[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ebaf5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean signal energy per class:\n",
      "Right imagined : 0.9171\n",
      "Right real     : 0.9238\n",
      "Left imagined  : 0.9144\n",
      "Left real      : 0.9249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "energy_by_class = defaultdict(list)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    label = sample[\"labels\"].item()\n",
    "    energy = sample[\"inputs\"].pow(2).mean().item()\n",
    "    energy_by_class[label].append(energy)\n",
    "\n",
    "print(\"Mean signal energy per class:\")\n",
    "for k in sorted(label_map):\n",
    "    print(f\"{label_map[k]:<15}: {np.mean(energy_by_class[k]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe9f3d",
   "metadata": {},
   "source": [
    "### NeuroGPT Teaser\n",
    "\n",
    "Each trial is already:\n",
    "- 22-channel (NeuroGPT format)\n",
    "- Normalized\n",
    "- Fixed-length\n",
    "- Labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a0e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 22, 500])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "batch = dataset[0]\n",
    "print(batch[\"inputs\"].shape)\n",
    "print(batch[\"labels\"].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d4728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9132f7b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da13dd5",
   "metadata": {},
   "source": [
    "### Loading the train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf2ad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108]\n",
      "MI_ME runs: [3, 4, 7, 8, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "all_subjects = list(range(1, 109))  # subject range\n",
    "print(\"Subjects:\", all_subjects)\n",
    "\n",
    "MI_ME_RUNS = [3,4, 7, 8,11, 12]\n",
    "print(\"MI_ME runs:\", MI_ME_RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473bd79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folds\n",
    "all_subjects = list(range(1, 110)) # Example for PhysioNet (109 subjects)\n",
    "train_folds = []\n",
    "val_folds = []\n",
    "test_folds = []\n",
    "\n",
    "# Use a step of 2 to match your '2 subjects per test fold' logic\n",
    "for i in range(0, len(all_subjects) - 4, 2):\n",
    "    # 1. Test Set: 2 subjects\n",
    "    test_subjects = all_subjects[i : i+2]\n",
    "    \n",
    "    # 2. Validation Set: The next 2 subjects\n",
    "    val_subjects = all_subjects[i+2 : i+4]\n",
    "    \n",
    "    # 3. Training Set: Everything else\n",
    "    # We exclude the indices used for test and validation\n",
    "    train_subjects = [s for s in all_subjects if s not in test_subjects and s not in val_subjects]\n",
    "\n",
    "    train_folds.append(train_subjects)\n",
    "    val_folds.append(val_subjects)\n",
    "    test_folds.append(test_subjects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8493ad67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
      "/home/jovyan/neuro-eeg/src/dataloader_simon.py:137: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from src.dataloader_simon import EEGMMIDBDataset\n",
    "\n",
    "\n",
    "train_dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=train_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "test_dataset_EEG = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=test_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n",
    "\n",
    "val_dataset = EEGMMIDBDataset(\n",
    "    root_path=str(DATA_PATH),\n",
    "    subjects=val_subjects,\n",
    "    runs=MI_ME_RUNS,\n",
    "    t_min=0.0,\n",
    "    t_max=4.0,\n",
    "    normalization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80e7231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train trials: 9484\n",
      "Validation trials : 180\n",
      "Test trials : 180\n",
      "Input shape: torch.Size([2, 22, 500])\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train trials:\", len(train_dataset))\n",
    "print(\"Validation trials :\", len(val_dataset))\n",
    "print(\"Test trials :\", len(test_dataset_EEG))\n",
    "\n",
    "batch = test_dataset_EEG[0]\n",
    "print(\"Input shape:\", batch[\"inputs\"].shape)   # (22, T)\n",
    "print(\"Label:\", batch[\"labels\"].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4df8716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution: Counter({2: 2386, 3: 2384, 1: 2363, 0: 2351})\n",
      "Test Label Distribution: Counter({1: 47, 2: 47, 3: 43, 0: 43})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Check Training Labels\n",
    "train_counts = Counter(train_dataset.labels)\n",
    "print(f\"Training Label Distribution: {train_counts}\")\n",
    "# Expected: {0: count_left, 1: count_right}\n",
    "\n",
    "# Check Test Labels\n",
    "test_counts = Counter(test_dataset_EEG.labels)\n",
    "print(f\"Test Label Distribution: {test_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb69e3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe7816a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 19:52:15.231757: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/micromamba/lib/python3.11/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "home = os.environ[\"HOME\"]\n",
    "python_imports = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder\"\n",
    "cache_root = f\"{home}/shared/DLN-2025W/notebook-eeg/Lab_GPT_based_EEG_decoder/\"\n",
    "sys.path.append(python_imports)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys \n",
    "sys.path.insert(0,os.path.join('NeuroGPT_mini/') )\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, f1_score\n",
    "import random\n",
    "import json\n",
    "\n",
    "### Import related to Transformer model (from files located in /NeuroGPT directory)\n",
    "\n",
    "from encoder.conformer_braindecode import EEGConformer\n",
    "from decoder.make_decoder import make_decoder\n",
    "from embedder.make import make_embedder\n",
    "from trainer.make import make_trainer\n",
    "from trainer.base import Trainer\n",
    "from decoder.unembedder import make_unembedder\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "with open(os.path.join(\"NeuroGPT_mini/config.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a5c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = {\"dst_data_path\" : os.path.join(python_imports, \"bciiv2a_eeg_npz/\"),\n",
    "         \"pretrained_model\" : os.path.join(\"NeuroGPT_mini/pytorch_model.bin\"), \n",
    "         \"log_dir\" :os.path.join(\"training_logs/\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9782d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Create Model object from embedder, decoder,\n",
    "    and unembedder (if not None).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    embedder: src.embedder.make_embedder\n",
    "        Instance of embedder class.\n",
    "    decoder: src.decoder.make_decoder\n",
    "        Instance of decoder class.\n",
    "    unembedder: src.unembedder.make_unembedder\n",
    "        Instance of unembedder class.\n",
    "        Only added to model if not None.\n",
    "\n",
    "    Methods\n",
    "    ----\n",
    "    forward(batch: Dict[str, torch.tensor])\n",
    "        Forward pass of model.\n",
    "    prep_batch(batch: Dict[str, torch.tensor])\n",
    "        Prepare batch for forward pass.\n",
    "    compute_loss(batch: Dict[str, torch.tensor])\n",
    "        Compute training loss.\n",
    "    from_pretrained(pretrained_path: str)\n",
    "        Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        embedder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,\n",
    "        unembedder: torch.nn.Module = None\n",
    "        ) -> torch.nn.Module:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.name = f'Embedder-{embedder.name}_Decoder-{decoder.name}'\n",
    "        self.encoder = encoder\n",
    "        self.embedder = embedder\n",
    "        self.decoder = decoder\n",
    "        self.unembedder = unembedder\n",
    "        self.is_decoding_mode = False\n",
    "        self.ft_only_encoder = False\n",
    "\n",
    "    def from_pretrained(\n",
    "        self,\n",
    "        pretrained_path: str\n",
    "        ) -> None:\n",
    "        \"\"\"Load pretrained model from pretrained_path.\n",
    "        Needs to point to pytorch_model.bin file.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f'Loading pretrained model from {pretrained_path}'\n",
    "        )\n",
    "\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            pretrained = torch.load(pretrained_path)\n",
    "\n",
    "        else:\n",
    "            pretrained = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
    "        \n",
    "        for k in self.state_dict():\n",
    "            \n",
    "            if k in pretrained:\n",
    "                assert pretrained[k].shape == self.state_dict()[k].shape,\\\n",
    "                    f'{k} shape mismatch between pretrained model and current model '+\\\n",
    "                    f'{pretrained[k].shape} vs {self.state_dict()[k].shape}'\n",
    "        \n",
    "        for k in pretrained:     \n",
    "            if k not in self.state_dict():\n",
    "                warnings.warn(\n",
    "                    f'Warning: /!\\ Skipping {k} from {pretrained_path} '\\\n",
    "                    'because it is not part of the current model'\n",
    "                )\n",
    "\n",
    "        # we set strict=False, because we can be sure\n",
    "        # that all relevant keys are in pretrained\n",
    "        self.load_state_dict(pretrained, strict=False)\n",
    "        \n",
    "    def switch_ft_mode(self, ft_encoder_only=False):\n",
    "        self.ft_only_encoder = ft_encoder_only\n",
    "\n",
    "    def switch_decoding_mode(\n",
    "        self,\n",
    "        is_decoding_mode: bool = False,\n",
    "        num_decoding_classes: int = None\n",
    "        ) -> None:\n",
    "        \"\"\"Switch model to decoding model or back to training mode.\n",
    "        Necessary to adapt pre-trained models to downstream\n",
    "        decoding tasks.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        is_decoding_mode: bool\n",
    "            Whether to switch to decoding mode or not.\n",
    "        num_decoding_classes: int\n",
    "            Number of classes to use for decoding.    \n",
    "        \"\"\"\n",
    "        self.is_decoding_mode = is_decoding_mode\n",
    "        \n",
    "        self.embedder.switch_decoding_mode(is_decoding_mode=is_decoding_mode)\n",
    "        self.decoder.switch_decoding_mode(\n",
    "            is_decoding_mode=is_decoding_mode,\n",
    "            num_decoding_classes=num_decoding_classes\n",
    "        )\n",
    "\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        return_outputs: bool = False\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"\n",
    "        Compute training loss, based on \n",
    "        embedder's training-style.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        return_outputs: bool\n",
    "            Whether to return outputs of forward pass\n",
    "            or not. If False, only loss is returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        losses: Dict[str, torch.tensor]\n",
    "            Training losses.\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        \"\"\"\n",
    "        (outputs, batch) = self.forward(\n",
    "            batch=batch,\n",
    "            return_batch=True\n",
    "        )\n",
    "        losses = self.embedder.loss(\n",
    "            batch=batch,\n",
    "            outputs=outputs\n",
    "        )\n",
    "\n",
    "        return (losses, outputs) if return_outputs else losses\n",
    "\n",
    "    def prep_batch(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor]\n",
    "        ) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"Prepare input batch for forward pass.\n",
    "        Calls src.embedder.prep_batch.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        \"\"\"\n",
    "        return self.embedder.prep_batch(batch=dict(batch))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: Dict[str, torch.tensor],\n",
    "        prep_batch: bool = True,\n",
    "        return_batch: bool = False\n",
    "        ) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of model.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as generated by src.batcher)\n",
    "        prep_batch: bool\n",
    "            Whether to prep batch for forward pass\n",
    "            by calling self.embedder.prep_batch\n",
    "        return_batch: bool\n",
    "            Whether to return batch after forward pass\n",
    "            or not. If False, only outputs of forward pass\n",
    "            are returned.\n",
    "\n",
    "        Returns\n",
    "        ----\n",
    "        outputs: torch.tensor\n",
    "            Outputs of forward pass.\n",
    "        batch: Dict[str, torch.tensor]\n",
    "            Input batch (as returned by prep_batch, \n",
    "            if prep_batch is True)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.encoder is not None:\n",
    "            #before prep_batch masking and things, we need to first let the splitted chunks of raw input through the encoder\n",
    "            features = self.encoder(batch['inputs'])\n",
    "            #attempt for trying fine-tune only the encoder, but the encoder cannot combine information across chunks.\n",
    "            if self.is_decoding_mode and self.ft_only_encoder:\n",
    "                outputs={'outputs': features, 'decoding_logits': features}\n",
    "                return (outputs, batch) if return_batch else outputs\n",
    "\n",
    "            b, f1, f2 = features.size()\n",
    "            nchunks = batch['inputs'].size()[1]\n",
    "            batch['inputs'] = features.view(b//nchunks, nchunks, f1*f2)\n",
    "        \n",
    "        if prep_batch:\n",
    "            if len(batch['inputs'].size()) > 3:\n",
    "                bsize, chunk, chann, time = batch['inputs'].size() \n",
    "                batch['inputs'] = batch['inputs'].view(bsize, chunk, chann*time)\n",
    "            batch = self.prep_batch(batch=batch)\n",
    "            # batch['inputs_embeds'] = batch['inputs_embeds'].view(bsize, chunk, chann, time)\n",
    "            # print(\"preparing batch\")\n",
    "        else:\n",
    "            assert 'inputs_embeds' in batch, 'inputs_embeds not in batch'\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        batch['inputs_embeds'] = self.embedder(batch=batch)\n",
    "        outputs = self.decoder(batch=batch)\n",
    "        \n",
    "        if self.unembedder is not None and not self.is_decoding_mode:\n",
    "            outputs['outputs'] = self.unembedder(inputs=outputs['outputs'])['outputs']\n",
    "\n",
    "        return (outputs, batch) if return_batch else outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd154e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model_config) : \n",
    "# Generate the model\n",
    "    \n",
    "    \n",
    "    ## Encoder\n",
    "    \n",
    "    if model_config[\"use_encoder\"] == True:\n",
    "        \n",
    "        chann_coords = None\n",
    "        encoder = EEGConformer(n_outputs=model_config[\"num_decoding_classes\"], n_chans=22, n_times=model_config['chunk_len'], ch_pos=chann_coords, is_decoding_mode=model_config[\"ft_only_encoder\"])\n",
    "        #calculates the output dimension of the encoder, which is the output of transformer layer.\n",
    "        model_config[\"parcellation_dim\"] = ((model_config['chunk_len'] - model_config['filter_time_length'] + 1 - model_config['pool_time_length']) // model_config['stride_avg_pool'] + 1) * model_config['n_filters_time']\n",
    "\n",
    "    else:\n",
    "        encoder = None\n",
    "        model_config[\"parcellation_dim\"] = model_config[\"chunk_len\"] * 22\n",
    "    \n",
    "    ## Embedder\n",
    "    \n",
    "    embedder = make_embedder(\n",
    "        training_style=model_config[\"training_style\"],\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        in_dim=model_config[\"parcellation_dim\"], # flattened, channel x chunk length\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers_embedding_model\"],\n",
    "        dropout=model_config[\"dropout\"],\n",
    "        n_positions=model_config[\"n_positions\"]\n",
    "    )\n",
    "    \n",
    "    ## Decoder\n",
    "    decoder = make_decoder(\n",
    "        architecture=model_config[\"architecture\"],\n",
    "        num_hidden_layers=model_config[\"num_hidden_layers\"],\n",
    "        embed_dim=model_config[\"embedding_dim\"],\n",
    "        num_attention_heads=model_config[\"num_attention_heads\"],\n",
    "        n_positions=model_config[\"n_positions\"],\n",
    "        intermediate_dim_factor=model_config[\"intermediate_dim_factor\"],\n",
    "        hidden_activation=model_config[\"hidden_activation\"],\n",
    "        dropout=model_config[\"dropout\"]\n",
    "    )\n",
    "   \n",
    "    \n",
    "    if model_config[\"embedding_dim\"] != model_config[\"parcellation_dim\"]:\n",
    "        unembedder = make_unembedder(\n",
    "            embed_dim=model_config[\"embedding_dim\"],\n",
    "            num_hidden_layers=model_config[\"num_hidden_layers_unembedding_model\"],\n",
    "            out_dim=model_config[\"parcellation_dim\"],\n",
    "            dropout=model_config[\"dropout\"],\n",
    "        )\n",
    "    else:\n",
    "        print(\"No Embedder and Unembedder!\")\n",
    "        unembedder = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(\n",
    "        encoder=encoder,\n",
    "        embedder=embedder,\n",
    "        decoder=decoder,\n",
    "        unembedder=unembedder\n",
    "    )\n",
    "    \n",
    "    if model_config[\"ft_only_encoder\"]:\n",
    "        model.switch_ft_mode(ft_encoder_only=True)\n",
    "    \n",
    "    if model_config[\"training_style\"] == 'decoding':\n",
    "        model.switch_decoding_mode(\n",
    "            is_decoding_mode=True,\n",
    "            num_decoding_classes=model_config[\"num_decoding_classes\"]\n",
    "        )\n",
    "    \n",
    "    if model_config[\"pretrained_model\"] is not None:\n",
    "        model.from_pretrained(model_config[\"pretrained_model\"])\n",
    "    \n",
    "    if model_config[\"freeze_embedder\"]:\n",
    "        for param in model.embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_decoder\"]:\n",
    "\n",
    "        ## TO DO : freeze the parameters of the decoder module :\n",
    "        for param in model.decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    if model_config[\"freeze_encoder\"]:\n",
    "        for name, param in model.encoder.named_parameters():\n",
    "            if 'fc.' in name \\\n",
    "            or 'final_layer' in name:\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        print('Frozen Encoder : Only the two last layers will be trained')\n",
    "    \n",
    "    if 'freeze_decoder_without_pooler_heads' in model_config \\\n",
    "        and model_config[\"freeze_decoder_without_pooler_heads\"]:\n",
    "        for name, param in model.decoder.named_parameters():\n",
    "            if 'pooler_layer' in name \\\n",
    "            or 'decoding_head' in name \\\n",
    "            or 'is_next_head' in name:\n",
    "    \n",
    "\n",
    "                continue\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    if model_config[\"freeze_unembedder\"] and unembedder is not None:\n",
    "        for param in model.unembedder.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff415bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model_config_PT_FT = config\n",
    "\n",
    "## Some important parameters in the architecture of the model \n",
    "\n",
    "model_config_PT_FT['pretrained_model'] = config_path['pretrained_model'] # Path to the file containing pretrained weights of the model, if model_config['pretrained_model'] = None the model is not pretrained\n",
    "model_config_PT_FT['embedding_dim'] = 1024 # Dimension of the latent representations in the model\n",
    "model_config_PT_FT['num_hidden_layers_embedding_model']= 1 # Number of hidden layers in the GPT model \n",
    "model_config_PT_FT['num_hidden_layers_unembedding_model']= 1 # Number of hidden layers on the unembedding module \n",
    "model_config_PT_FT['num_hidden_layers']= 6  #Number of hidden layers in the encoder module\n",
    "model_config_PT_FT['filter_time_length']= 25 #Size of the kernel of the temporal convolution layer \n",
    "model_config_PT_FT['stride_avg_pool']= 15  # Stride size used in the average-pooling operation\n",
    "model_config_PT_FT[\"freeze_encoder\"] = False # Whether to freeze the encoder (True = no training on encoder parameters, only the classification layer)\n",
    "model_config_PT_FT[\"learning_rate\"] = 0.001\n",
    "\n",
    "model = make_model(model_config_PT_FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "117586d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config_PT_FT = config\n",
    "\n",
    "# Some important paramerter to build up the training stategy\n",
    "\n",
    "trainer_config_PT_FT['model_init'] = make_model # Function used to instanciate a model\n",
    "trainer_config_PT_FT['run_name'] = 'Finetunning_PTFT' # Name of the run to save logs in a directory \n",
    "trainer_config_PT_FT['train_dataset'] = train_dataset \n",
    "trainer_config_PT_FT['validation_dataset'] = val_dataset\n",
    "trainer_config_PT_FT['output_dir'] = os.path.join(config_path['log_dir'], trainer_config_PT_FT['run_name']) # Where to save training logs\n",
    "\n",
    "trainer_config_PT_FT['training_steps'] = 3000 # Number of training steps\n",
    "trainer_config_PT_FT['validation_steps'] = 500 # Number of validation steps\n",
    "# Whether to freeze the encoder (True = no training on encoder parameters)\n",
    "trainer_config_PT_FT['model_save_steps'] = config[\"training_steps\"]*2\n",
    "trainer_config_PT_FT['log_every_n_steps'] = 1000\n",
    "trainer_config_PT_FT['eval_every_n_steps'] = 500\n",
    "trainer_config_PT_FT['warmup_ratio'] = 0.1\n",
    "trainer_config_PT_FT['optim'] = \"adamw_torch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28d2e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuro-eeg/NeuroGPT_mini/encoder/base.py:178: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from NeuroGPT_mini/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer = make_trainer(model_init=lambda: make_model(model_config_PT_FT), config = trainer_config_PT_FT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e82784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Layer for Classification created.\n",
      "Loading pretrained model from NeuroGPT_mini/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 01:35, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.994600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved to :  training_logs/checkpoint-3000\n",
      "End of the training ! \n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "print(\"End of the training ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e19d1097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been saved to :  training_logs/Finetunning_PTFT/model_final\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(config[\"log_dir\"], trainer_config_PT_FT['run_name'], 'model_final')\n",
    "trainer.save_model(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b5e5c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96cc792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, \n",
    "    cohen_kappa_score, \n",
    "    f1_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "def get_performance_from_trainer(trainer, test_dataset):\n",
    "    \"\"\"\n",
    "    This function takes as input a trainer that has already been trained \n",
    "    (So the the trainer.train() method must already been called on it)\n",
    "    And it returns the a dictionnary with the different performance metrics. \n",
    "    \"\"\"\n",
    "    test_prediction_ = trainer.predict(test_dataset)\n",
    "    test_preds = test_prediction_.predictions\n",
    "    test_labels = test_prediction_.label_ids\n",
    "    pred_label=np.argmax(test_preds, axis=1)\n",
    "\n",
    "    true_label = test_labels\n",
    "    pred_label = pred_label \n",
    "    balanced_acc = balanced_accuracy_score(true_label, pred_label)\n",
    "\n",
    "    kappa = cohen_kappa_score(true_label, pred_label)\n",
    "\n",
    "    weighted_f1 = f1_score(true_label, pred_label, average='weighted')\n",
    "\n",
    "    cm = confusion_matrix(true_label, pred_label)\n",
    "    \n",
    "    return {\n",
    "        'Balanced Accuracy': balanced_acc,\n",
    "        'Cohen s Kappa': kappa, \n",
    "        'Weighted F1-score': weighted_f1,\n",
    "        'Confusion Matrix': cm \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ab600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Balanced Accuracy': 0.4816922315685304, 'Cohen s Kappa': 0.30484798685291703, 'Weighted F1-score': 0.449925790206443, 'Confusion Matrix': array([[32,  6,  3,  2],\n",
      "       [27,  8,  9,  3],\n",
      "       [ 5,  3, 29, 10],\n",
      "       [ 4,  3, 19, 17]])}\n"
     ]
    }
   ],
   "source": [
    "perf_PT_FT = get_performance_from_trainer(trainer, test_dataset_EEG)\n",
    "print(get_performance_from_trainer(trainer, test_dataset_EEG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "174d5d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.4817\n",
      "Cohen's Kappa: 0.3048\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1. Get metrics from your existing function\n",
    "metrics = get_performance_from_trainer(trainer, test_dataset_EEG)\n",
    "cm = metrics['Confusion Matrix']\n",
    "\n",
    "# 2. Define the class labels (since you filtered for Left/Right only)\n",
    "class_names = ['Left Hand', 'Right Hand']\n",
    "\n",
    "# 3. Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "\n",
    "plt.title('Confusion Matrix: PhysioNet (Left vs. Right)')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Print the other metrics for context\n",
    "print(f\"Balanced Accuracy: {metrics['Balanced Accuracy']:.4f}\")\n",
    "print(f\"Cohen's Kappa: {metrics['Cohen s Kappa']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89040b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neuro EEG",
   "language": "python",
   "name": "neuro-eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
